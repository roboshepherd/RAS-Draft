%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%%
%%
%% $Id: elsarticle-template-num.tex 4 2009-10-24 08:22:58Z rishi $
%%
%%
%\documentclass[preprint,12pt]{elsarticle}
%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}
%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
 \documentclass[draft,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%\usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
%\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

% custom packages
\usepackage[nolist]{acronym}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{natbib}
\usepackage[colorlinks=false]{hyperref}
\usepackage{graphicx,hypernat,subfig}
\usepackage{geometry}
\usepackage{color}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{listings,program}
\usepackage{algorithmicx,algpseudocode}
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}
% \biboptions{}
\journal{Robotics and Autonomous System}

%% custom commands
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}} 
%=================================================================
\begin{document}
%%
\begin{acronym}
%==== A B C D ====
\acro{AFM}{attractive field model}
\acro{AGV}{automated guided vehicle}
\acro{APCD}{average production completion delay}
\acro{APMW}{average pending maintenance work-load}
%\acro{AS}{active space}
\acro{BMS}{biology-inspired manufacturing system}
\acro{CCD}{charge-coupled device}
%\acro{CCM}{centralized communication mode}
\acro{DEM}{data and event management}
\acro{DOL}{division of labour}
%==== E F G H ====
%\acro{EPSRC}{Engineering and Physical Sciences Research Council}
\acro{GigE}{Gigabyte Ethernet}
\acro{GIL}{Global Interpreter Lock}
%\acro{GPS}{global positioning system}	
\acro{GSNC}{global sensing - no communication}
%\acro{GUI}{graphical user interface}
\acro{HEAD}{hybrid event-driven architecture on D-Bus}
%====  I J K L ====
%\acro{IF}{independent founders}
%\acro{INS}{indoor navigation system}
\acro{IPC}{inter-process communication}
%\acro{IR}{infrared}
%\acro{LCM}{local communication mode}
\acro{LSLC}{local sensing - local communication}
%==== M N O P ====
\acro{MOM}{maintenance only mode}
\acro{MRS}{multi-robot system}
\acro{MRTA}{multi-robot task allocation}
\acro{P2P}{peer-to-peer}
%\acro{PF}{potential field}
\acro{PMM}{production and maintenance mode}
%=====  Q R S T ====
\acro{RCC}{robot-controller client}
%\acro{RW}{random walk}
\acro{SDK}{software-development kit}
%\acro{SF}{swarm founders}
\acro{SHM}{shared memory}
%\acro{SI}{swam intelligence}
%\acro{SO}{self-organization}
%\acro{SR}{self-regulation}
%\acro{SRS}{swarm robotic system}
\acro{TPS}{task perception server}
%==== U V W X ====
%==== Y Z ==== 
\end{acronym}
%-----------------------------------------------------
\begin{frontmatter}
%%
%% Title, authors and addresses
%%
%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}
%%
\title{Self-regulated Multi-robot Task~Allocation:\\ A Taxonomy and Comparison of Centralized and Local Communication Strategies}
%%
%% use optional labels to link authors explicitly to addresses:
\author[label1]{Md Omar Faruque Sarker and Torbj{\o}rn S. Dahl}
\address[label1]{Cognitive Robotics Research Centre\\
Newport Business School,
Allt-yr-yn Campus\\ %Allt-yr-yn Avenue\\
Newport, NP20 5DA,
United Kingdom.\\
Mdomarfaruque.Sarker \vline Torbjorn.Dahl@newport.ac.uk}
%\address[label1]{<address>}
%
%\author{}
%
%\address{}
%
\begin{abstract}
To deploy a large group of autonomous robots in dynamic multi-tasking environments, a suitable multi-robot task-allocation (MRTA) solution is required. This paper proposes to solve the MRTA problem using a set of previously published generic rules for division of labour derived from the observation of ant, human and robotic social systems. The concrete form of these rules, the \textit{attractive filed model} (AFM), provides sufficient abstraction to local communication and sensing which is uncommon in existing MRTA solutions. We have validated the effectiveness of AFM to address MRTA  using two bio-inspired communication and sensing strategies: ``global sensing - no communication'' and ``local sensing - local communication''. The former is realized using a centralized communication system and the latter is emulated under a peer-to-peer local communication scheme. They are applied in a  manufacturing shop-floor scenario using 16 e-puck robots. A flexible multi-robot control architecture, \textit{hybrid event-driven architecture on D-Bus}, has been outlined which uses the state-of-the-art D-Bus interprocess communication.  Based-on the organization of task-allocation, communication and interaction among robots, a  novel taxonomy of MRTA solutions has been proposed to remove the ambiguities found in existing MRTA solutions. Besides, a set of domain-independent metrics, e.g., plasticity, task-specialization and energy usage, has been formalized to compare the performances of the above two strategies.
\end{abstract}
%%
%\begin{keyword}
%multi-robot system \sep multi-robot task allocation
%% keywords here, in the form: keyword \sep keyword
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
%\end{keyword}
%%
\end{frontmatter}
%%
%%
%% Start line numbering here if you want
%%
% \linenumbers
%%==================================================================
%% main text
\section{Introduction}
\label{sec:intro}
%%
%% [MRTA problem at a glance]
%-------------------------------
 Multi-robot systems can provide improved performance, fault-tolerance and robustness in complex and distributed tasks through parallelism and redundancy \cite{Arkin1998,Parker+2006}. However in order to get potential benefits of \aclp{MRS}, we need to answer a common research question. \textit{How can we allocate tasks among multiple robots dynamically?} Traditionally, this issue has been identified as the \acfi{MRTA} \cite{Gerkey+2004}. This issue can be treated as the \acfi{DOL} among robots, analogous to the DOL in biological and human social systems\footnote{Although the term ``division of labour'' is often used in biological literature and the term ``task-allocation'' is primarily used in multi-agent literature,  in this paper we have used these terms interchangeably.} \cite{Sendova-Franks+1999}.

MRTA is generally identified as the question of assigning tasks in an appropriate time to the appropriate robots considering the changes of the environment and/or the performance of other team members \cite{Gerkey+2003}. This is a {\em NP-hard} optimal assignment problem where optimum solutions can not be found quickly for large and complex problems \cite{Parker2008}.The complexities of the distributed MRTA problem arise from the fact that there is no central planner or coordinator for task assignments, and in a large \acl{MRS}, generally robots have limited capabilities to sense, to communicate and to interact locally. None of them has the complete knowledge of the past, present or future actions of other robots.

Early research on predefined task-allocation was dominated by intentional coordination \cite{Parker2008}, use of dynamic role assignment \cite{Chaimowicz2002} and market-based bidding approach \cite{Dias+2006}. Under these approaches, robots use direct task-allocation method, often to communicate with group members for negotiating on tasks. These approaches are intuitive, comparatively straight forward to design and implement and can be analysed formally. However, these approaches typically works well only when the number of robots are small ($\leq 10$) \cite{Lerman+2006}.

On the other hand, self-organized task-allocation approach relies on the emergent group behaviours, such as emergent cooperation \cite{Kube+1993}, adaptation rules \cite{Liu+2007} etc. They are more robust and scalable to large team sizes. However, most of the robotic researchers found that self-organized task-allocation approach is difficult to design, to analyse (formally) and to implement in real robots. The solutions from these systems are also sub-optimal. It is also difficult to predict exact behaviours of robots and overall system performance.

Within the context of the Engineering and Physical Sciences Research Council (EPSRC) project, ``Defying the Rules: How Self-regulatory Systems Work'', we have proposed to solve the above mentioned self-regulated DOL problem in an alternate way \cite{Arcaute+2008}. Our approach is inspired from the studies of emergence of task-allocation in both biological and human social systems. We have proposed four generic rules to explain self-regulation in those social systems. These four rules are: \textit{continuous flow of information}, \textit{concurrency}, \textit{learning} and \textit{forgetting}, all of them will be explained later. Primarily these rules deal with the issue of deriving local control laws for regulating an individual's task-allocation behaviour that can facilitate the DOL in the entire group. In order to  employ these rules in the individual level, we have developed a formal model of self-regulated DOL, called the \acfi{AFM}.

In biological social systems, communications among the group members, as well as sensing the task-in-progress, are two key components of self-organized DOL. In robotics, existing self-organized task-allocation methods rely heavily upon local sensing and local communication of individuals for achieving self-organized task-allocation. However, AFM differs significantly in this point by avoiding the strong dependence on the local communications and interactions found in many existing approaches to MRTA. AFM provides a rich abstraction to this requirement through a system-wide continuous flow of information about tasks, agent states etc. This flow of information can be achieved by using both centralized and decentralized communication modes under explicit and implicit communication strategies.

In order to enable continuous flow of information in our \acl{MRS}, we have implemented two types of sensing and communication strategies inspired by the self-regulated DOL found in two types of social wasps: {\em polistes} and {\em polybia} \cite{Jeanne1999}. Depending on the group size, these species follow different strategies for communication and sensing of tasks. Polistes wasps are called the {\em independent founders} in which reproductive females establish colonies alone or in small groups (in the order of $10^2$), but independent of any sterile workers. On the other hand, polybia wasps are called the {\em swarm founders} where a swarm of workers and queens initiate colonies consisting of several hundreds to millions of individuals.

The most notable difference in the organization of work of these two social wasps is: independent founders do not rely on any cooperative task performance while swarm founders interact with each-other locally to accomplish their tasks. The work mode of independent founders can be considered as {\em global sensing - no communication (GSNC)} where the individuals sense the task requirements throughout a small colony and do these tasks without communicating with each other. On the other hand, the work mode of swarm founders can be treated as {\em local sensing - local communication (LSLC)} where the individuals can only sense tasks locally due to large colony-size and they can communicate locally to exchange information, e.g. task-requirements (although their exact mechanism is unknown).In this study, we have used these two sensing and communication strategies to compare the performance of the self-regulated DOL of our robots under AFM. 

The main contributions of this paper are as follows:
\begin{itemize}
\item Interpretation of AFM, an inter-disciplinary generic model of division of labour, as a basic mechanism of self-regulated MRTA.
\item Validation of the model through experiments with reasonably large number of real robots i.e., 16 e-puck robots.
\item Comparisons of the performances of two bio-inspired sensing and communication strategies in achieving self-regulated MRTA.
\item Development of a flexible multi-robot control architecture using D-Bus inter-process communication technology.
\item Classification of MRTA solutions based on three major axes: organization of task-allocation, interaction and communication.
\end{itemize}
%%===================================================================
\section{Related work}
\label{sec:bg}
%%
\begin{figure*}
\centering
\includegraphics[width=0.8\linewidth, angle=0]
{./images/ta-categories.eps}
\caption{Classification of MRTA solutions.}
\label{fig:mrta-classification} % Give a unique label
\end{figure*}
%%
Since 90s, MRTA many robot control architectures   have been solely designed to address MRTA issue from different perspectives. Based-on the high-level design of those solutions, here we have classified them into two major categories: 1) predefined or intentional task-allocation and 2) bio-inspired self-organized task-allocation. Fig. \ref{fig:mrta-classification} illustrates our classification.

In most of the traditional multi-robot system, task allocation is done using well-defined models of tasks and environments. Here it is assumed that the system designer has the precise knowledge about tasks, robot-capabilities etc. Many flavours of the type of task-allocation can be found in the literature. Knowledge-based and multi-agent based approaches use various knowledge-based techniques to represent tasks, robot capabilities etc. One of the early well-known MRTA architecture of this category was ALLIANCE  in which each robot models the ability of team-members to perform tasks by observing their current task performances and collecting relevant task quality statistics e.g. time to complete tasks \cite{Parker1998}. Robots use these models to select a task that benefit  the group as a whole. 

Similar to  ALLIANCE, multi-agent based task allocation also  use both centralized and decentralized approaches for allocating tasks among  its  peers. \citet{Shen+2001} presented a detailed categorization where in a multi-agent system task allocation can be done by using various agents ranging from a central supervising agent or a few mediator agents to  all independent agents. 

As a feasible alternative to the above common multi-agent based task-allocation techniques, many researchers have been following the market-based bidding approach \citet{Dias+2006}. Originated from the Contract-Net Protocol, market-based approach can be implemented as a centralized auctioning system or as a combination of {\em a few auctioneers -- all bidders} or, independently {\em all auctioneers -- all bidders}. For example, in a completely distributed system, when a robot needs to perform a task for which it does not have necessary expertise or resources, it broadcasts a task-announcement message, often with  a expiry time of that message. Robots, that received the message and can perform that task, return a bid message. The initiating robot or {\em  manager} selects one (or more) bidder, called as {\em contractor}, and offers the opportunity to complete the task. The choice of contractor is done by the manager with a mutual agreement with contractor that maximizes the individual profits.

Under role or value-based task-allocation scheme, each role assumes several specific tasks and each robot selects roles that best suit their individual skills and capabilities \cite{Chaimowicz2002}. In this case, robots are typically heterogeneous, each one having variety of different sensing, computation and effector capabilities. Here robot-robot or robot-environment interactions are designed as a part of the organization. In multi-robot soccer \cite{Stone+1999}, positions played by different  robots are often defined as roles, e.g. goal-keeper, left/right defender, left/right forwarder etc. 

Under control-theoretic approaches, a model of the system is usually developed that converts the task specification into an objective function to be optimized. This model typically  uses  the rigid  body dynamics of the robots assuming the masses and other parameters well-known. Control laws of individual robots are derived either by analytically or by run-time iterations. Unlike most other approaches where task-allocation problem is taken as discrete, control-theoretic approaches can produce continuous  solutions. The formalisms of these systems allow system designer to check the system's controllability, stability and related other properties.  These systems typically use some degree of centralization, e.g. choosing a leader robot.  Example of control-theoretic approach include: multi-robot formation control \cite{Belta+2004}, multi-robot box-pushing \cite{Pereira+2003}  etc.

Predefined task-allocation through few other approaches are also present in the literature. For example, inspired by the vacancy chain phenomena in nature, \citet{Dahl+2004} proposed a vacancy chain scheduling algorithm for a restricted class of MRTA problems in spatially classifiable domains.

Task performance in self-organized approaches relies on the collective behaviours resulted from the local interactions of many simple and mostly homogeneous (or interchangeable) agents. Robots choose their tasks independently using the principles of self-organization, e.g. positive and negative feedback mechanisms, randomness. Moreover interaction among individuals and their environment are modulated by the stigmergic, local and broadcast communications.  Among many variants of self-organized task-allocation, most common type is threshold-based task-allocation \cite{Bonabeau+1999}. In this approach, a robot's decision to select a particular task depends largely on its perception of stimulus (demand for a task) and its corresponding response threshold for that task. 

Under deterministic response-threshold approach, each robot has a fixed or deterministic activation threshold for each task that needs to be performed. It continuously perceives or monitors the stimulus of all tasks that reflect the relative urgencies of tasks. When a particular task-stimuli exceeds a predefined  threshold the robot starts working on that task and gradually decreases this stimuli. When the task-stimuli falls below the fixed threshold the robot abandons that task. This type of approach has been effectively applied in foraging \cite{Krieger+2000,Liu+2007}, aggregation \cite{Agassounon+2002}. This fixed response-threshold can initially be same for all robots \cite{Jones+200}, or they can be different according robot capabilities or configuration of the system \cite{Krieger+2000}. Adaptive response threshold model changes or adapts the threshold over time. Response-threshold decreases often due to performance of a task and this enables a robot  to select that particular task more frequently or in other words it learns about that task \cite{Bonabeau+1999,Agassounon+2002}. 

Unlike deterministic approach, where robots always respond to a task-stimuli that has a largest stimulus above the threshold,  probabilistic approach offers a selection process based-on a probability distribution. Robots  always have small nonzero probabilities  for all tasks.

Most predefined task-allocation solutions are proposed within the context of a known or controlled environment where the modelling of tasks, robots, environments etc. becomes feasible. Note that here tasks can be arbitrarily complex that often require relatively higher sensory and processing abilities of robots. Robot-team can be consists of homogeneous or heterogeneous individuals, having different capabilities based on the variations in their hardware, software etc. But the uncertainty of the environment is assumed to be minimum. 

On the other hand, bio-inspired self-organized MRTA solutions are free from extensive modelling of environment, tasks or robot capabilities. Most of the existing research considers very simple form of one global task e.g. foraging, area cleaning, box-pushing etc. This is due to the fact that major focus of this approach is limited mainly to design individual robot controllers in such a way that a few simple  or {\em specific} tasks can be accomplished. More research is needed to verify the capabilities of self-organized approach in doing multiple complex tasks. At this moment, the bottom line remains as ``select simple robots for simple tasks (self-organized approach) and complex robots for complex tasks (predefined approach)''.

Both of the above task-allocation approaches expose their relative strengths and weaknesses when they are put under real-time experiments with variable number of robots and dynamic tasks. In an arbitrary event handling domain, \citet{kalra+2007}  compared between self-organized and predefined market-based task-allocation,  where they found that predefined  task-allocation was more efficient when the information was accurate, but threshold-based  approach offered similar quality of allocation at a fraction of cost  under noisy environment.  

\citet{Gerkey+2003} presented a comparative study of  the complexity and optimality of key architectures, e.g.  ALLIANCE \cite{Parker1998}, BLE \cite{Werger2001}, M+ \cite{Botelho+1999}, MURDOCH \cite{Gerkey+2002}, First piece auctions \cite{Zlot+2002} and Dynamic role assignment \cite{Chaimowicz2002}, all of them relied upon predefined task-allocation methods. The computational and communication requirements of these MRTA solutions were expressed in terms of number of robots and tasks. Although this study does not explicitly measures the scalability of those key architectures, it clearly shows us that many predefined task-allocation solutions will fail to scale well in challenging environments  when the number of  robots and tasks will increase, under the given limited overall communication bandwidth and processing power of individual robots. 

From above discussions we can see that, self-organized task-allocation methods are advantageous as they can provide fully distributed, scalable and robust MRTA solutions through redundancy and parallelism in task-executions. Moreover, the interaction and communication requirements of robots can also be kept under a minimum limit.  So for large multi-robot system, self-organized task-allocation methods  can potentially be selected, if the complex tasks can be divided into simple pieces that can be carried out by multiple simple robots in parallel with limited communication and interaction requirements.
%%
\section{A three-axes taxonomy of MRTA solutions}
\label{sec:taxonomy}
%%
\begin{figure}
\centering
\includegraphics[width=\linewidth, angle=0]
{./images/mrta-lines.eps}
%figure caption is below the figure
\caption{ Three major axes of complexities in MRTA}
\label{fig:mrta-complexities} % Give a unique label
\end{figure}
%%
In order to characterize both predefined and self-organized approaches in terms of their deployment, we propose three distinct axes: 1) organization of task-allocation (X), 2) degree of interaction (Y) and 2) degree of communication (Z). Fig. \ref{fig:mrta-complexities} depicts these axes with a reference point $O$. These axes can be used to measure the complexities involved in various kinds of MRTA problems and the design of their solutions. 

In Fig. \ref{fig:mrta-complexities}, X axis represents the number of active nodes that provides the task-allocation to the group. For example, in any predefined  task-allocation approach, we can use one external centralized entity or one of the robots (aka leader) to manage the task-allocation. In many predefined methods, e.g. in market-based systems,  multiple nodes can act as mediators or task-allocators that we have discussed before. Under predefined task-allocation approach,  a small number of robots can have fully distributed task-allocation where each robot acts as an independent task-allocator (e.g. as discussed before in ALLIANCE architecture). 

Most of the self-organized task-allocation methods are fully distributed, i.e. they allocate their tasks independently without the help of a centralized entity. However, they might be dependent on external entities for getting status or descriptions of tasks. Recent studies on swarm-robotic flocking by \citet{Celikkanat+2008} show that a swarm can be guided to a target by a few informed individuals (or leaders) while  maintaining the self-organizing principles of task-allocation. Task-allocation of a swarm of robots  just by one central entity may be rare since one of the major spirits of swarm robotic system is to become fully distributed.

In Fig. \ref{fig:mrta-complexities},  Y axis corresponds to the level of robot-robot interaction present in the system. Group-level interaction can be classified into various levels: collective, cooperative, coordinative and collaborative \cite{Parker2008}. The presence of interaction can be due to the nature of the problem, e.g. cooperation is necessary in co-operative transport tasks. Alternately, this interaction can be a design choice where interaction can improves the performance of the team, e.g. cooperation in cleaning a work-site is not necessary but it can help to improve the  efficiency of this task. 

Y axis can also be used to refer to the degree of coupling present in the system.  In case of collective interaction, robots merely co-exist, i.e.  they may not be aware of each other except treating others as obstacles. Many other multi-robot systems are loosely-coupled where robots can indirectly infer some states of the environment from their team-mates' actions.  But in many cases, e.g. in  co-operative transport, robots not only recognize others as their team-mates, but also they coordinate their actions. Thus they form a  tightly coupled system. This level of interaction and coupling also gives us the information about potential side-effects of failure of an individual robot. Tightly coupled systems with high degrees of interactions among the robots  suffer from the performance loss if some of the robots removed from the system.

The Z axis of Fig. \ref{fig:mrta-complexities} represents the communication overhead of the system. This can be the result of the interactions  of robots under a given task-allocation method. As we have discussed before various task-allocation methods rely upon variable degrees of robot-robot communications.  On the other hand, the communication capabilities of individual robots can limit (or expand) the level of interaction can be made  in a given group. Thus in one way, considering the interaction requirements of a MRTA problem, the system designer can  select suitable communication strategies that both minimizes the communication overhead and maximizes the performance of the group. And in other way, the communication capabilities of robots can guide a system designer to design interaction rules of robot teams, e.g. the specification of robot's on-board camera  can determine the degree of possible visual interactions among robots. The suitable trade-offs between these two axes: communication and interaction can give us a balanced design of our MRTA solutions.

The central issue of this paper is to determine the role of communication and sensing strategies under an adaptive response-threshold task-allocation method. So we have focused to examine the benefits of traversing along the various axes of Fig. \ref{fig:mrta-complexities}. In this paper, we are interested on two distinct lines: 1) distributed task-allocation, with no direct robot-robot interaction and communication, say line $OX_{n}$ ($n$ being the number of robots)  and 2) distributed task-allocation, with no direct robot-robot interaction, but varying degrees of local communications, say line $X_{n}Z_{l}$  ($Z_{l}$ being a local broadcast communication strategy that involves $l$ number of peers in communication).
%%============================================================
\section{Robotic interpretation of the Attractive Field Model}
\label{sec:afm}
%%
The construction of AFM has been achieved through a series of collaborative interactions among our project partners. From the biological experiments of ants colonies {\em Temnothorax albipennis} we  inferred the bottom-up rules and roles of feedback in collective performance of ants brood-sorting and nest construction after emigration to a new site. We  also analysed the observational data from the self-organized infrastructural development of an {\em eco-village} by an open community of volunteers resided in Ireland. These studies helped us to formalize the generic rules into a concrete model  and to validate this model by deploying it in our robot controllers within the context of a manufacturing shop-floor scenario. In this section, we have described the robotic validation of AFM, with a brief presentation on interpretations of AFM from different social perspectives.
\subsection{Generic framework}
\label{afm:framework}
Inspired from the DOL in ants, humans and robots,  we  have proposed the following four rules that are the potential ingredients to obtain self-regulation in any social system. In this dissertation, these rules are mentioned as the {\em generic rules of self-regulation}.

\textbf{Rule 1: Continuous flow of information.} Self-regulatory social systems establish the continuous minimum flow of information over the period of time when self-regulation can be defined. This should help to maintain at least two states of an agent: 1) receiving information about task(s) and 2) ignoring information or doing no task. The up-to-date information should reflect  the changes of the system i.e. it encodes the necessary feedback for the agents. Thus, this property will act as the basis of the state switching of agents, between these two minimum states or, among multiple states e.g. in case of multiple tasks or many sub-states of a single task.

At the individual level, information is processed differently by each individual, and is certainly not constant nor continuous. In addition, there can be lower and upper thresholds on the amount of info necessary for DOL to take place. The time scale at the individual level is very small compared to the system level's time scale.We can approximate the propagation of information at this macro time scale as the continuous flow of information.  In the model, emphasize is given to whether the information is used e.g. stimulation to perform a task, or unused e.g. random walk.

\textbf{Rule 2: Sensitization}. Self-regulatory social systems allow the differentiation in the use of  (or access to) information, e.g. through sensitization or learning of some tasks. This differentiation is regulated by the characteristics of the system, e.g. the ability of the agents to learn tasks that are repeatedly performed.

\textbf{Rule 3: Concurrence.} Self-regulatory social systems include concurrent access to information from different spatial positions with certain preferences. This preference is not fixed and can change with the dynamics of the system. 

\textbf{Rule 4: Forgetting.} Self-regulatory social systems include forgetting, e.g. the ability of the agents to diminish information over time, if not used. The system determines the amount of information being released, and this changes over time. For example, specialists might have to attend an emergency situation and switch tasks that contributes to the forgetting of old task experiences. This is considered as crucial to allow flexibility in the system.
%%
\begin{figure}
\centering
\includegraphics[width=0.7\linewidth, angle=0]{./images/AFM-Diag2.eps}
\caption{The attractive filed model (AFM)}
\label{fig:afm} % Give a unique label
\end{figure}
Having this general framework of self-regulatory social systems, we can now formalize AFM that will describe the properties of individual  agents and the system as a whole. In terms of networks, the model is a bipartite network, i.e. there are two different types of nodes. One set of nodes describes the sources of the attractive fields and the other set describes the agents. Links only exist between different types of nodes and they encode the flow of information so that, even if there is no direct link between two agents, their interaction is taken into account in the information flow. This is an instance of {\em weak} interaction. The strength of the field primarily depends upon the distance between the task and the agent. This relationship is represented using weighted links. Besides, there is a permanent field that represents the {\em no-task} or  option for ignoring information. The model can be mapped to a network as shown in Fig. \ref{fig:afm}. The correspondence is given below:
\begin{enumerate}
\item Source nodes (o) are tasks that can be divided between a number of agents.
\item Agent nodes (x) an be ants, human,  robots etc.
\item The attractive fields correspond to stimuli to perform a task, and these are given by the black solid lines.
\item When an agent performs a task, the link becomes different, and this is denoted in the figure by a dashed line. Agents linked to a source by a red line are the agents currently doing that task. 
\item The field of ignoring the information (w) corresponds to the stimulus to random walk, i.e. the no-task option, and this is denoted by the dotted lines in the graph. 
\item Each of the links is weighted. The value of this weight describes the strength of the stimulus that the agent experiences. In a spatial representation of the model, it is easy to see that the strength of the field depends on the physical distance of the agent to the source. Moreover, the strength can be increased through sensitisation of the agent via experience (learning). This distance is not depicted in the network, it is represented through the weights of the links. In the figure of the network (Fig. \ref{fig:afm}), the nodes have arbitrary places. Note that even though the distance is physical in this case, the distance in the model applied to other systems, needs not to be physical. It can represent the accessibility to the information, the time the information takes to reach the receiver, etc. 
\end{enumerate}
In summary, from the above diagram of the network, we can see that each of the agents is connected to each of the fields. This means that even if an agent is currently involved in a task, the probability that it stops doing it in order to pursue a different task, or to random walk, is always non-zero. The weighted links express the probability of an agent to be attracted to each of the fields.
%%--------------------------------------------------------------------
\subsection{Relationship of AFM with self-organization}
\label{afm:so}
\begin{figure*}
\centering
\includegraphics[width=0.9\linewidth, angle=0]
{./images/self-org-2.eps}
%figure caption is below the figure
\caption{\small Four generic rules establish the self-regulated DOL in social systems}
\label{fig:afm-rules} % Give a unique label
\end{figure*}

It is interesting to note that our proposed four generic rules can be considered as  the four major foundations of a self-organized system (Fig.  \ref{fig:afm-rules}). Self-organized systems exhibit four distinct perspectives known as so-called ingredients or properties of self-organization \cite{Camazine+2001}. However, it is not clear how those properties can come into existence. Here, we have described the four underlying mechanisms that explains how self-organization can be realized in different social systems using our generic framework of self-regulation. From our understanding, we can explain it in the following ways.

Firstly, multiple interactions become meaningful when {\em continuous flow of information} occurs  by exchanging signals or cues among agents or their environment  that regulates their behaviours. This, in turn, contribute to the task-allocation  and task-switching in the social level.  In swarm intelligence literature, multiple interactions are often described as an essential ingredient of self-organization. However, interactions without definite purposes may not contribute to the self-organization.

Secondly, in swarm intelligence, positive feedback has been attributed as another mechanism of  self-organization. But it is not easy to understand what creates positive feedback in a social system. Possible answers might be the characteristic of the environment e.g. ants select shorter path since density of pheromones becomes higher and thus more ants becomes attracted in that path, the gradual decrease of response-threshold of individuals which increases the probability of selecting a task etc.  To make the answer more concrete, we have explicitly attributed {\em sensitisation} or learning as a mechanism of positive feedback. There might exist other mechanisms too. But clearly sensitisation will be one of the reliable mechanisms for achieving positive feedback.

Thirdly, similar to positive feedback, we have proposed {\em forgetting} that contributes to provide negative feedback about a task or decreasing the probability to select it. Other negative feedback mechanisms can be implemented by assigning a saturation level to each task which is also present in our model, for details see \citet{Arcaute+2008}.

Finally, creating  artificial amplification of fluctuations or stochastic events is not a straight-forward issue. It throws  many open questions. Does a system designer intentionally impose irregularity in task-performance of agents?  Is random movement  enough for simulating randomness in a system?
Since emergencies do not always pop-up on request, we provide the rule of {\em concurrency} that enables agents to  maintain even a small amount of probability of selecting a low-priority, or less sensitized or distant task. This concurrency mechanism provides a high-degree of robustness in the system such that all tasks can be attended even if specialization of agents delays them in switching to some of the tasks.
%%
\subsection{Interpretation of AFM in multi-robot systems}
\label{afm:mrs-interpretation}
The interpretation of AFM in a multi-robot system also follows almost exactly as in generic interpretation. However, in order to make the interpretation more concrete, let us consider a manufacturing shop floor scenario, where $N$ number of autonomous mobile robots are required to attend $J$ number of shop tasks spread over a fixed area $A$. Let these tasks be represented by a set of small rectangular boxes resembling to manufacturing machines.

%%
Let $R$ be the set of robots ${r_1, r_2,...,r_n}$. Let a task $j$ has an associated task-urgency $\phi_j$ indicating its relative importance over time.
If a robot attends a task $j$ in the $x^{th}$ time-step, the value of $\phi_j$ will decrease by an amount $\delta_{\phi_{INC}}$ in the $(x+1)^{th}$ time-step.
On the other hand, if a task has not been served by any robot in the $x^{th}$ time-step, $\phi_j$ will increase by another amount  $\delta_{\phi_{DEC}}$  in $(x+1)^{th}$ time-step. Thus
%-- Phi update
urgency of a task is updated by the following rules.
\begin{equation}
 If\hspace*{0.15cm}the\hspace*{0.15cm} task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}being\hspace*{0.15cm} done:\hspace*{0.15cm}  \phi_j \rightarrow   \phi_j \hspace*{0.15cm} + \delta_{\phi_{INC}}
\label{eqn:delta-phi1}
\end{equation}
%%
\begin{equation}
 If\hspace*{0.15cm}the \hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}being\hspace*{0.15cm}done:\hspace*{0.15cm}  \phi_j \rightarrow   \phi_j \hspace*{0.15cm} - n\hspace*{0.10cm}\delta_{\phi_{DEC}}
\label{eqn:delta-phi2}
\end{equation}
Eq. \ref{eqn:delta-phi1} refers to a case where no robot attend to task $j$ and Eq. \ref{eqn:delta-phi2} refers to another case where $n$ robots are concurrently performing the task $j$.

In order to complete a task $j$, a robot $r_i$ needs to be within a fixed boundary $D_{j}$. If a robot completes a task $j$ it learns about it and this will influence $r_i$'s likelihood of selecting that task in future, say through increasing  its sensitization to $j$ by a small amount, $k_{INC}$. Here, the variable affinity of a robot $r_i$ to task $j$ is called as its {\em sensitization} $k^{i}_{j}$. If a robot $i$ does not do a task $j$ for some time, it forgets about $j$ and $k^i_j$ is decreased, by another small amount, say $k_{DEC}$ .
Thus a robot's task-sensitization update follows these rules.
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} + \hspace*{0.15cm} k_{INC}
\label{eqn:k-inc}
\end{equation}
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} - \hspace*{0.15cm} k_{DEC}
\label{eqn:k-dec}
\end{equation}

According to AFM, all robots will establish attractive fields to all tasks due to the presence of a system-wide continuous flow of information. The strength of these attractive fields will vary according to the dynamic distances between robots and tasks, task-urgencies and corresponding sensitizations of robots. Simplifying the generic implementation of AFM from \citet{Arcaute+2008}, we can formally encode this stimuli of attractive field as follows.
%% S
\begin{equation}
S_{j}^{i} = tanh\{\frac{k_{j}^{i}}{d_{ij}+\delta } \phi _{j}\}
\label{eqn:afm1}
\end{equation}
%--P(Task)
\begin{equation}
S^{i}_{RW} = tanh \left \{ 1 -  \frac{ \sum_{j=1}^{J} S^{i}_{j}}{J + 1} \right \}
\label{eqn:afm2}
\end{equation}
%-- P(RW)
\begin{equation}
P_{j}^{i} = \frac{S_{j}^{i}}{\sum_{j=0}^{J} S_{j}^{i}} \hspace*{0.25cm}where,\hspace*{0.25cm}S^{i}_{0} = S^{i}_{RW}   
\label{eqn:afm3}
\end{equation}

Eq. \ref{eqn:afm1} states that the stimuli of a robot $r_i$ to a particular task $j$, $S^{i}_{j}$ depends on $r_i$'s spatial distance to $j$ ($d_{ij}$), level of sensitization to $j$ ($k_{j}^{i}$), and perceived urgency of that task ($\phi _{j}$). In  Eq. \ref{eqn:afm1}, we have used a very small constant value $\delta$ to avoid division by zero, in the case when a robot has reached to a task. Since $S^{i}_{j}$ is a probability function, it is chosen as a $tanh$ in order to keep the values between 0 and 1. Eq. \ref{eqn:afm2} suggests us how we can estimate the stimuli of random walk or no-task option. This stimuli of random walk depends on the sum of stimulus of $J$ real tasks. Here, random-walk is also considered as a task. Thus the total number of tasks become $J+1$. The probability of selecting each task has been determined by a probabilistic method outlined in Eq. \ref{eqn:afm3} which states that the probability of choosing a task $j$ by robot $r_i$ is directly proportional to its calculated stimuli $ S^i_j$. Finally, let $T_a$ be the allocated time to accomplish a task. If a robot can enter inside the task boundary within $T_a$ time it waits there until $T_a$ elapsed. Otherwise it will select a different task.
%%============================================================ 
\section{AFM based task-allocation solution}
\label{sec:mrta}
We have designed a set of  manufacturing shop-floor scenario experiments for validating the effectiveness of our AFM in producing self-regulated MRTA.  The overall aim of this design is to analyse the various properties of task-allocation and related other issues. In this section, we have described our manufacturing shop-floor scenario and our task-allocation solution for robot-controllers.
%%
\begin{figure*}
\centering
\includegraphics[width=0.9\linewidth, angle=0]
{./images/VSP.eps}
%figure caption is below the figure
\caption{A manufacturing shop-floor production and maintenance cycle}
\label{fig:vsp}  % Give a unique label
\end{figure*}
%--------------------------------------------
\subsection{A manufacturing shop-floor scenario}
\label{afm:vms}
By extending our interpretation of AFM in multi-robot system, we can set-up manufacturing shop-floor  scenario. Here, each task represents a manufacturing machine that is  capable of producing goods from raw materials, but they also require constant maintenance works for stable operations. Let $W_{j}$ be a finite number of material parts that can be loaded into a machine $j$ in the beginning of its production process and in each time-step, $\omega_{j}$ units of material parts can be processed  ($\omega_{j} \ll W_{j} $). So let $\Omega_{j}^{p}$ be the initial production workload of $j$ which is simply: $W_{j} / \omega_{j}$ unit.

We assume that all machines are identical. In each time step, each machine always requires a minimum threshold number of robots, called hereafter as {\em minimum robots per machine ($\mu$)}, to meet its constant maintenance work-load, $\Omega_{j}^{m}$ unit. However, if $\mu$ or more robots are present in a machine for production purpose, we assume that, no extra robot is required to do its maintenance work separately. These robots, along with their production jobs, can do necessary maintenance works concurrently. For the sake of simplicity, here we consider $\mu$ = 1.

Now let us fit the above production and maintenance work-loads and task performance of robots into a unit task-urgency scale. Let us divide our manufacturing operation into two subsequent stages: 1) \acfi{PMM}, and 2) \acfi{MOM}. Initially a machine starts working in PMM and does production and maintenance works concurrently. When there is no production work left, then it  enters into MOM. Fig. \ref{fig:vsp} illustrates this scenario for a single machine.

Under both modes, let $\alpha_{j}$ be the amount of workload occurs in a unit time-step if no robot serves a task and it corresponds to a fixed task-urgency $\Delta \phi_{INC}$. On the other hand, let us assume that in each time-step, a robot, $i$, can decrease a constant workload $\beta_{i}$ by doing some maintenance work along with doing any available production work. This  corresponds to a negative task urgency: $- \Delta \phi_{DEC}$. So, at the beginning of production process, task-urgency, occurred in a machine due to its production work-loads, can be encoded by Eq. \ref{eqn:task-urgency-prod-init}.
\begin{equation}
%\small
\Phi_{j, INIT}^{PMM} = \Omega_{j}^{p} \times \Delta \phi_{INC} + \phi_{j}^{m0}
\label{eqn:task-urgency-prod-init}
\end{equation}
where $\phi_{j}^{m0}$ represents the task-urgency due to any initial maintenance work-load of $j$.
Now if no robot attends to serve a machine, each time-step a constant maintenance workload of $\alpha_{j}^{m}$ will be added to $j$ and that will increase its task-urgency by $\Delta \phi_{INC}$. So, if $k$ time steps passes without any production work being done, task urgency at $k^{th}$ time-step will follow Eq. \ref{eqn:task-urgency-prod-case1}.
\begin{equation}
\Phi_{j, k}^{PMM} =\Phi_{j, INIT}^{PMM} + k \times \Delta \phi_{INC}
\label{eqn:task-urgency-prod-case1}
\end{equation}
However, if a robot attends to a machine and does some production works from it, there would be no extra maintenance work as we have assumed that $\mu$ = 1. Rather, the task-urgency on this machine will decrease by $\Delta \phi_{DEC}$ amount. If $\nu_{k}$ robots work on a machine simultaneously at time-step $k$, this decrease will be: $\nu_{k} \times \Delta \phi_{DEC}$. So in such cases, task-urgency in $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{PMM} = \Phi_{j, k}^{PMM} - \nu_{k} \times \Delta \phi_{DEC}
\label{eqn:task-urgency-prod-case2}
\end{equation}
At a particular machine $j$, once $\Phi_{j, k}^{PMM}$ reaches to zero, we can say that there is no more production work left and this time-step $k$ can give us the {\em production completion time} of $j$, $T_{j}^{PMM}$. Average production time-steps of a shop-floor with M machines can be calculated by the following simple equation.
\begin{equation}
T_{avg}^{PMM} = \frac{1}{M} \sum_{j=1}^{M} T_{j}^{PMM} 
\label{eqn:avg-pmm}
\end{equation}
$T_{avg}^{PMM}$ can be compared with the minimum number of time-steps necessary to finish production works, $T_{min}^{PMM}$. This can only happen in an ideal case where all robots work for production without any random walking or failure. We can get $T_{min}^{PMM}$ from the total amount of work load and maximum possible inputs from all robots. If there are M machines and N robots, each machine has $\Phi_{INIT}^{PMM}$ task-urgency, and each time-step robots can decrease N $\times$ $\Delta \phi_{DEC}$ task-urgencies, then the theoretical $T_{min}^{PMM}$ can be found from the following Eq. \ref{eqn:min-pmm}.
%
%\begin{multicols}{2}
%\small
\begin{equation}
T_{min}^{PMM} = \frac{M \times \Phi_{INIT}^{PMM}}{N \times \Delta \phi_{DEC}} 
\label{eqn:min-pmm}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\zeta_{avg}^{PMM} = \frac{T_{avg}^{PMM} - T_{min}^{PMM}}{T_{min}^{PMM}} 
\label{eqn:appd}
\end{equation}
%\end{multicols}
Thus we can define $\zeta_{avg}^{PMM}$, \acf{APCD} by following Eq. \ref{eqn:appd}:
%%
When a machine enters into MOM, only $\mu$ robots are required to do its maintenance works in each time step. So, in such cases, if no robot serves a machine, the growth of task-urgency will follow Eq. \ref{eqn:task-urgency-prod-case1}. However, if $\nu_{k}$ robots are serving this machine at a particular time-step $k^{th}$ , task-urgency at $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{MOM} = \Phi_{j, k}^{MOM}- (\nu_{k} - \mu) \times \Delta \phi_{DEC}
\label{eqn:task-urgency-maint-case}
\end{equation}
By considering $\mu = 1$, Eq. \ref{eqn:task-urgency-maint-case} will reduces to Eq. \ref{eqn:task-urgency-prod-case2}. Here, $\Phi_{j, k+1}^{MOM}$ will correspond to the {\em pending maintenance work-load} of a particular machine at a given time. This happens due to the random task switching of robots with a no-task option (random-walking). Interestingly PMW will indicate the robustness of this system since higher PMW value will indicate the delay in attending maintenance works by robots. We can find the \acfi{APMW} per time-step per machine, $\chi_{j}^{MOM}$ (Eq. \ref{eqn:sigle-pmw}) and average PMW per machine per time-step, $\chi_{avg}^{MOM}$ (Eq. \ref{eqn:avg-pmw}).
%\begin{multicols}{2}
%\small
\begin{equation}
\chi_{j}^{MOM}= \frac{1}{K} \sum_{k=1}^{K} \Phi_{j, k}^{MOM}
\label{eqn:sigle-pmw}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\chi_{avg}^{MOM}= \frac{1}{M} \sum_{j=1}^{M} {\chi_{j}^{MOM}}
\label{eqn:avg-pmw}
\end{equation}
%\end{multicols}
%----------------------------------------------------------------
\subsection{Robot-controller algorithms}
\textbf{Task-allocation algorithm:}\\
\textbf{Stage 1.} In the beginning of our task-allocation algorithm, we count the total number of tasks and initialize the sum of the stimuli all tasks to zero. Then for each task, we extract its pose, urgency, sensitisation from input data.\\  \textit{CalculateTaskDistance()} function calculates the Euclidian distance between a task and a the robot by taking the current robot-pose and static task-pose as the input. These values are enough to get a task's stimuli based on Eq. \ref{eqn:afm1}. In this loop finally we update \textit{TaskRecords} for using it in next task-allocation cycle. We get the random-walk task's stimuli from Eq. \ref{eqn:afm2}. It requires total number of shop-tasks and sum of their stimulus.\\

\textbf{Algorithm 1: Self-regulated task-allocation based on AFM}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:task-selector}
\State $\textbf{Input: } AllTaskInfo, RobotPose, TaskRecords, DeltaDistance$
\State $\textbf{Output: } SelectedTaskID$
\State \COMMENT {Stage 1: Get  sum  of stimulus of all tasks}
\State $TotalTasks \gets$  Total number of tasks $\in AllTaskInfo$  
\State $ TaskStimuliSum \gets 0 $
\ForAll {$ Task \in AllTaskInfo $} 
\State $ TaskPose \gets  $ Task-position  $ \in Task$
\State $ TaskUrgency \gets $ Task-urgency $ \in Task$
\State $ TaskSensitization \gets $ Task-sensitization $\in Task$
\State $ DistToTask \gets$
\textbf{CalculateTaskDistance(}
\newline
$RobotPose$, $TaskPose$\textbf{)}
\State $ TaskStimuli \gets  $ \textbf{CalculateTaskStimuli(}
\newline
$DistToTask, TaskSensitization, TaskUrgency, DeltaDistance$\textbf{)}
\State $ TaskStimuliSum \gets$  $TaskStimuliSum + TaskStimuli$
\State $ TaskRecords \gets $ \textbf{UpdateTaskRecords(\\}$TaskStimuli,DistToTask, TaskUrgency,$\\ $TaskSensitization\textbf{)}$
\EndFor
%%
\State $RandomWalkStimuli \gets $ \textbf{CalculateRandomWalkStimuli(\\}$TotalTasks,$ %\hspace*{4.5cm}
 $TaskStimuliSum$\textbf{)}
\State $ AllStimuliSum \gets TaskStimuliSum + RandomWalkStimuli $
%%
\State \COMMENT {Stage 2: Find probability of doing each task }
\State $ TaskID \gets 0 $ 
\While {$ TaskID \leq TotalTasks $} 
\State $ TaskStimuli \gets $ Task-stimuli $\in TaskRecords(TaskID)$
\State $ TaskProbability \gets  $ \textbf{GetTaskProbability(\\}$TaskStimuli, AllStimuliSum$\textbf{)}
\State $ TaskProbabilityRange \gets $
\newline
 \textbf{ConvertTaskProbabilityIntoRange(}\\ $TaskProbability$\textbf{)}
\State $ TaskRecords \gets  $ \textbf{UpdateTaskRecords(}$TaskProbability$\textbf{)}
\EndWhile
%%
\State \COMMENT {Stage 3: Draw a random-number to match TaskID}
\State $ RandomNum \gets  $ 
\newline
\textbf{GetRandomNumber(}$0,$ \textbf{Max(}$TaskProbabilityRange$\textbf{))}
\While {$ TaskID \leq TotalTasks $} 
\State $ RangeStart \gets  $ \textbf{Min(}$TaskProbabilityRange (TaskID)$\textbf{)}
\State $ RangeEnd \gets  $ \textbf{Max(}$TaskProbabilityRange (TaskID)$\textbf{)}
\If {$  RandomNum \geq RangeStart$ \newline $\hspace*{.25cm}\&\& \hspace*{.25cm} RandomNum  \leq  RangeEnd $}
\State $ SelectedTaskID \gets TaskID $ 
\EndIf
\EndWhile
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
%%
\textbf{Stage 2.} In the second stage of our task-allocation algorithm, we  find the probability of each task (including random-walk) based on Eq. \ref{eqn:afm3}. Then this probability value of each task, between 0 and 1, is rounded to the closest two-digit fractions and multiplied by 100 and put into a linear scale. For example, if two tasks probability values are: 0.15 and  0.25, the probability range of first  task becomes 0 to 15 and for second task, it becomes 16 to 40.\\
%% 
\textbf{Stage 3.} After converting each task's probability values into a linear range, we use a random-number generator that draws a random-number between 0 and the highest value of task-probability range, say 40 for the previous example. Then this random number is compared against the task probability range of each task. For the above example, if the random-number becomes 37, our task-probability range checking function selects \textit{Task2} since 37 falls between 16 to 40. Under this probabilistic method, the task with larger probability range has a  higher chance to be selected, but low probability tasks are also got selected time-to-time.\\

\textbf{Algorithm 2: Robot's learning and forgetting of tasks based on AFM}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:update-sz}
\State $\textbf{Input: }  TaskRecords, LeranRate, ForgetRate, SelectedTaskID$
\State $\textbf{Output: }$ Updated $TaskSensitisation \in TaskRecords$
\ForAll {$ Task \in TaskRecords $} 
\State $ TaskID \gets  $ ID $\in Task$
\State $ TaskSensitization \gets  $   Sensitisation $ \in Task$
\If {$  TaskID \equiv SelectedTaskID $}
\State $ TaskSensitization \gets $ \textbf{Max(}$1, (TaskSensitization + LeanRate)$\textbf{)}
\Else
\State $ TaskSensitization \gets $ \textbf{Min(}$0, (TaskSensitization - ForgetRate)$\textbf{)}
\EndIf
\EndFor
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
%%
\textbf{Robot learning and forgetting algorithm:}\\
Algorithm 4.2 lists the pseudo-code for updating the robot's task-sensitization values. Along with previously mentioned \textit{TaskRecords}, and  \textit{SelectedTaskID}, it takes two other inputs: \textit{LeranRate} ($\Delta k_{INC} $) and \textit{ForgetRate} ($\Delta k_{INC} $) as outlined in Eq. {eqn:k-inc} and {eqn:k-dec} respectively.  In addition to that it also keep the value of task-sensitization between the fixed limit of 0 and 1.
%==============================================================
\section{Local P2P communication model (LPCM)}
From our understanding of different kinds of communication strategies of biological social systems, this is obvious that an effective LSLC strategy can greatly enhance the self-regulated MRTA.  In fact, most  researchers in the field of swarm robotics now acknowledge that LSLC is the one of the most critical components of a swarm robotic system, as global behaviours emerges from local interactions among the individuals and their environment.

In this study, we have used the concepts of pheromone active-space of ants to realize our simple LSLC scheme. As discussed in Sec. \ref{bg:bio-comm}, ants use various chemical pheromones with different active spaces (or communication ranges) to communicate different messages with their group members. Ants sitting near the source of this pheromone sense and respond quicker than others who wander in far distances. Thus both communication and sensing occurs within a small communication range\footnote{Although, generally communication and sensing are two different issues, however within the context of our self-regulated DOL, we have broadly viewed sensing as the part of communication process, either implicitly via environment, or explicitly via local peers.}. We have used this concept of communication range or locality in our LPCM.

In order to find a suitable  range (or radius) of communication and sensing, some researchers have argued that this range can be set at design time based on the capabilities of robots \cite{Agassounon+2002}. Some other researchers have argued that they can be dynamically varied over time depending on the  cost of communication and sensing, e.g. density of peers, ambient noise in the communication channels, or even by aiming for maximizing information spread  \cite{Yoshida+2000}. In this study, we have followed the former approach as our robots do not have the precise hardware to dynamically vary their communication and sensing ranges.
%%---------------------------------------------------------
\subsection{General characteristics of LPCM}
Our LPCM relies on the local P2P communications among robots. we have assumed that robots can communicate to its nearby peers within a certain communication radius, $r_{comm}$ and they can sense tasks within another radius $r_{task}$. They exchange communication signals reliably without any significant loss of information. A robot $R_1$ is a {\em peer} of robot $R_2$, if spatial distance between $R_1$ and $R_2$ is less than this $r_{comm}$.
Similarly, when a robot comes within this $r_{task}$ of a task, it can sense the status of this task. Although the communication and sensing  range can be different based on robot capabilities, we have considered them same for the simplicity of our implementation.

Local communication can also give robots similar task information as in centralized communication. In this case, it is not necessary for each robot to communicate with every other robot to get information on all tasks. Since robots can random walk and explore the environment we assume that for a reasonably high robot-to-space density, all task will be known to all robots after an initial exploration period. In order to update the urgency of a task, robots can estimate the number of robots working on a task in two ways:  by either using their sensory perception (e.g., camera) or  doing local P2P communication with others.

We characterize our communication model in terms of three fundamental issues of communication \cite{Gerkey+2001}. 
\begin{enumerate}
\item Message content: {\em what to communicate?}
\item Communication frequency: {\em when to communicate?}
\item Target message recipients: {\em with whom to communicate?}
\end{enumerate}
%%
In a typical multi-robot system, message content can be categorized into two types: state of each individual robot and target task (goal) information \cite{Balch2005}. The latter can also be subdivided into two types: 1) an individual robot's target task information and 2) information of all available tasks found in the system.

Regarding the first issue, our communication model is open. Robots can communicate with their peers with any kind of message. Our model addresses the last two issues very specifically. Robots communicate only when they meet their peers within a certain communication radius ($r_{comm}$). Although in case of an environment where robots move relatively faster the peer relationships can also be changed dynamically. But this can be manipulated by setting the signal frequency and robot to space density to somewhat reasonably higher value.

In terms of target recipients, our model differs from a traditional publish/subscribe communication model by introducing the concept of dynamic subscription. In a traditional publish/subscribe communication model, subscription of messages happens prior to the actual message transmission. In that case prior knowledge about the subjects of a system is necessary. But in our model this is not necessary as long as all robots uses a common addressing convention for naming their incoming signal channels. In this way, when a robot meets with another robot it can infer the address of this peer robot's channel name by using a shared rule. A robot is thus always listening to its own channel for receiving messages from its potential peers or message publishers. On the other side, upon recognizing a peer, a robot sends a message to this particular peer. So here neither it is necessary to create any custom subject name-space  \cite{Gerkey+2001} nor we need to hard-code information in each robot controller about the knowledge of their potential peers {\em a priori}. Subscription is done automatically based on their respective $r_{comm}$.
%
%%----------------------------------------------------------------
\subsection{Implementation algorithm}
%%
\textbf{\small Algorithm 3: Locality based P2P Communication Model}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\label{alg:lpcm}
\State $\textbf{Input: } RobotID, r_{comm}, r_{task}, TaskInfoDB, RobotPose,$\\ \hspace*{1cm}$ListeningBuffer, EmissionBuffer$
\State $\textbf{Output: }$ updated $TaskInfoDB$
\State \COMMENT {Perception of a task, if the robot is within $r_{task}$}
\State $ TaskPose \gets $ Estimate/get pose of a task within $r_{task}$
\State $ TaskUrgency \gets $ Estimate/get urgency of a task within $r_{task}$
\State $ TaskInfo \gets (TaskPose, TaskUrgency) $ 
\State $TaskInfoDB \gets$
\newline
\textbf{UpdateTaskInfoDB(}$TaskInfo$\textbf{)}
% P2P Interaction, listen signal
\State \COMMENT {Listening \textit{\textit{LocalTaskInfo}} signal(s) from peers}
\State $ RobotPeers \gets $ Identify/get a list of peers within $r_{comm}$
\ForAll {peer $\in RobotPeers$}
\If {(caught a \textit{\textit{LocalTaskInfo}} signal from nearby peer)}
\State $ListeningBuffer \gets $ \textit{\textit{LocalTaskInfo}} of peer
\State $TaskInfoDB \gets$
\newline 
\textbf{UpdateTaskInfoDB(}$ListeningBuffer$\textbf{)}
\EndIf
\EndFor
%%
\State \COMMENT {Emitting own \textit{\textit{LocalTaskInfo}} signal to peers}
\State $ EmissionBuffer \gets TaskInfoDB$
\ForAll {peer $\in RobotPeers$}
\State \textbf{EmitLocalTaskInfoSignal(}peer, $EmissionBuffer$ \textbf{) }
\EndFor
\State $RobotPeers \gets 0$
\end{algorithmic}
%\vspace{-3mm} 
%\HRule\\
Within the context of our self-regulated MRTA experiments under AFM,  we have formalized the following three aspects of LPCM into an implementation algorithm. 
\begin{enumerate}
\item Local sensing of peers and tasks.
\item Listening to the task-information peer signals.
\item Emitting local task-information signals to peers.
\end{enumerate}
%%
From Algorithm 5.1, we see that a robot controller is initialized with its specific $RobotID$ and default values of $r_{comm}$ and $r_{task}$ that correspond to the robot's communication and sensing range respectively. We have assumed that these values are same for all robots and for all tasks. Initially a robot has no information about tasks, i.e. {$TaskInfoDB$} is empty. It has neither received nor transmitted any information yet, i.e. corresponding data buffers, $ListeningBuffer$ and $EmissionBuffer$, are also empty. Upon sensing a task, robot determines the task's pose and urgency of that task (according AFM rules described in Sec. \ref{afm:mrs-interpretation}). This is not strictly necessary as this information can also be available from alternate sources, e.g. via communicating with a TPS which is discussed later.

Robot controller then executes the \textbf{UpdateTaskInfoDB()} that modified the robot's information about the corresponding task. In second step, robot senses its nearby peers located within $r_{comm}$ and add them in $RobotPeers$. The potential textit{LocalTaskInfo} signal reception from a  peer again triggers the \textbf{UpdateTaskInfoDB()} function. In the last step, robot emits its own task information as a \textit{LocalTaskInfo} signal to its peers. Finally it cleans up the current values of $RobotPeers$ for running a new cycle.
%====================================================================
\section{Experiments}
\label{sec:expt}
%%
We have designed a set of manufacturing shop-floor scenario experiments for validating the effectiveness of our AFM in producing self-regulated MRTA. The overall aim of this experiments is to compare the various properties of self-regulated MRTA under GSNC and LSLC strategies. These experiments are grouped into four series labelled using the following letters: A, B C and D. Series A and B experiments are done using a centralized communication system under GSNC strategy and Series C and D experiments are carried out using an emulated local P2P communication under LSLC stategty. Below we describe the observables, parameters and implementation of our experiments.
%----------------------------------------------------------
\subsection{Observables}
\textbf{Plasticity:} %As we have discussed in Sec. \ref{bg:def:dol},  
Self-regulated DOL can be characterised by plasticity and task-specialization, in both macroscopic and microscopic levels. Within manufacturing shop-floor context, plasticity refers to the collective ability of the robots to switch from doing no-task option (random-walking) to doing a task (or vice-versa) depending on the work-load present in the system. Here we expect to see that most of the robots would be able to engage in tasks when there would be high workloads (or task-urgencies) during PMM. Similarity, when there would be low workload in case of MOM only a few robots would do the task, rest of them would either be idle (not doing any task) or perform a random-walk.  The changes of task-urgencies and the ratio of robots engaged in tasks can be good metrics to observe plasticity in MRTA.\\
%%
\textbf{Task-specialization:} Under heavy work-load most of the robots should attend to tasks. But self-regulated DOL is always accompanied with task-specializations of agents. That means that few robots will be more active than others. From AFM, we can see that after doing a task a few times, a robot will soon be sensitized to it. Therefore, from the raw log of task-sensitization of robots, we can be able to find the pattern of task-sensitization of robots per task basis. If a few robots specializes on a particular task that will help to reduce traffic near the task and improves overall efficiency of the system. Thus, at the end of our production cycle in manufacturing shop-floor scenario, we can count the percentage of robots specializes on each task in our experiments.\\
%%
\textbf{Quality of task-performance:} As discussed in Sec. \ref{afm:vms} we can measure the quality of MRTA from the APCD. It first calculates the ideal minimum production time and then finds the delay in production process from the actual production completion data. Thus this will indicate how much more time is  spent in the production process due to the self-regulation of robots in this distributed task-allocation scheme.  In order to calculate APCD, we can find the production completion time for each task from the raw log of task-urgency and make an average from them.\\
%%
\textbf{Robustness:} In order to see if our system can respond to the gradually increasing workloads,  we can measure APMW within the context of our manufacturing shop-floor scenario. This can show the robustness of our system where a task can be  unattended for long time. When a task is not being served by any robot for some time we can see that its urgency will rise and robots will respond to this dynamic demand. For measuring APMW we need only the task-urgency data.\\
%%
\textbf{Flexibility:} From the design of AFM, we know that robots that are not doing a task will be de-sensitized to it or forget that task. So at an overall low work-load (or task urgency), less robots will do the tasks and hence less robots will have the opportunity to learn tasks. From the shop-floor work-load data, we can confirm the presence of flexibility in MRTA.\\
%%
\textbf{Energy-efficiency:} In order to characterize the energy-efficiency in MRTA we can log the pose data of each robot that can give us the total translations occurred by all robots in our experiments. This can give us a rough indication of energy-usage by our robots. \\
%%
\textbf{Information flow:} Since AFM requires a system-wide continuous flow of information, we can measure the communication load to bench-mark our implementation of communication system. This bench-mark data can be used to compare among various communication strategies. Here we can measure  how much task-related information, i.e. task-urgency, location etc. are sent to the robots at each time step. This  amount of information or communication load can be constant or variable depending on the design of the communication system.
%%
\textbf{Scalability:} In order to see the effects of scaling on MRTA, we have designed two series of experiments. {\em Series A} corresponds to a small group where we have used 8 robots, 2 tasks under an arena of 2 $m^2$. We have doubled these numbers in {Series B}, i.e. 16 robots, 4 tasks under an arena of 4 $m^2$. This proportional design can give us a valuable insight about the effects of scaling on self-regulated MRTA. All of the above metrics of Set A and Set B can be compared to find those scalability effects.

Thus, in order to observe the above properties of self-regulated MRTA , we have designed our experiments to record the following  observables in each time-step.
\begin{enumerate}
\item Task-urgency of each task ($\phi$).
\item Number of robots engaged in each task.
\item Task-sensitizations ($k$) of robots.
\item Pose data of robots.
\item Communication of task-information message with robots.  
\end{enumerate}
%%
\begin{table}
\caption{Experimental parameters of Series A \& B experiments}
\label{table:params}
\begin{center}
\begin{tabular}{|p{2in}|c|}
\hline Parameter & Series A $\mid$ Series B\\
\hline Total number of robots ($N$) & \hspace*{0.1cm} 8 $\mid$ 16\\
\hline Total number of tasks ($M$) & 2 $\mid$ 4\\
\hline Experiment area ($A$) & 2 $m^2$ $\mid$  4 $m^2$\\
\hline Initial production work-load/machine ($\Omega_{j}^{p}$) & 100 unit \\
\hline Task urgency increase rate ($\Delta\phi_{INC}$) & 0.005\\
\hline Task urgency decrease rate ($\Delta\phi_{DEC}$) & 0.0025\\
\hline Initial sensitization ($K_{INIT}$) & 0.1\\
\hline Sensitization increase rate ($\Delta k_{INC}$) & 0.03\\
\hline Sensitization decrease rate ($\Delta k_{DEC}$) & 0.01\\
\hline
\end{tabular}
\end{center}
\end{table}
%%
\begin{figure}
\centering
\includegraphics[height=7cm, angle=0]{./images/CentralizedComm.eps}
\caption{\small A centralized communication scheme} % for implementing AFM}
\label{fig:ccm} % Give a unique label
\end{figure}
%------------------------------------------------------------
\subsection{Parameters}
Table \ref{table:params} lists a set of essential parameters of our experiments. We intend to have a set-up that is relatively complex, i.e., with a high number of robots and tasks in a large area. The diameter of the marker of our e-puck robot is 0.08m. So, if we put 4 robots in an area of one square meter, this will give us a robot-occupied-space to free-space ratio of about 1:49 per square meter. This ratio reasonable in order to allow the robots to move at a speed of 5 cm/sec without much interference to each other. 

The initial values of task urgencies correspond to 100 units of production work-load without any maintenance work-load as outlined in Eq. \ref{eqn:task-urgency-prod-init}. We choose a limit of 0 and 1, where 0 means no urgency and 1 means maximum urgency. Same rule applies to sensitisation, where 0 means no sensitisation and 1 means maximum sensitisation. This also implies that if sensitization is 0, task has been forgotten completely. On the other hand, if sensitization is 1, the task has been learnt completely. We choose a default sensitization value of 0.1 for all tasks. The following relationships are maintained for selecting task-urgency and sensitization parameters.
\begin{equation}
\Delta\phi_{INC} = \frac{\Delta\phi_{DEC} \times N}{2 \times M}
\label{eqn:task-urgency}
\end{equation}
%
\begin{equation}
\Delta k_{DEC} = \frac{\Delta k_{INC}} {M - 1} 
\label{eqn:sensitization}
\end{equation}
%
Eq. \ref{eqn:task-urgency} establishes the fact that task urgency will increase at a higher rate than that of its decrease. As we do not like to keep a task left unattended for a long time we choose a higher rate of increase of task urgency. This difference is set on the basis of our assumption that at least half of the expected number of robots (ratio of number of robots to tasks) would be available to work on a task. So they would produce similar types of increase and decrease behaviours in task urgencies.

Eq. \ref{eqn:sensitization} suggests that the learning will happen much faster than the forgetting. The difference in these two rates is based on the fact that faster leaning gives a robot more chances to select a task in next time-step and thus it becomes more specialized on it.

%% local
Our local communication experiments follow the similar design of experimental parameters and observables of Series B experiments as outlined above. Table \ref{table:local-expt-design} highlights the major parameters of these experiments. Here, we can see that there are two new parameters in Series C and Series D experiments, i.e. communication and sensing ranges. For the sake of simplicity, both of these values are kept same in both series of experiments.
Series D uses larger ranges that enables our robot to capture more task information at a time. That is similar to  ``global sensing and global communication'' of information by the robots, since in a large group of robots, it is not practical that a robot communicates with all other robots. On the other hand, Series C uses the half of the range values of Series D. This enables our robots to capture less information, that mimics a true LSLC strategy. The main motivation for using two different ranges is to find any significant difference in performance from these two types of experiments.
%%
\begin{table}
\caption{Experimental parameters of Series C \& D experiments}
\label{table:local-expt-design}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline Parameter & \hspace*{0.2cm} Series C $\mid$ Series D\\
\hline task-perception range ($r_{task}$) & $0.5 m \mid 1 m$\\
\hline Communication range ($r_{comm}$) & $0.5 m \mid 1 m$\\
\hline Total number of robots ($N$) & 16 \\
\hline Total number of tasks ($M$) & 4 \\
\hline Experiment area ($A$) & 4 $m^2$\\
\hline
\end{tabular}
\end{center}
\end{table}
% 
%-------------------------------------------------------
\subsection{Implementation}
\label{afm:impl}
%%
\begin{figure*}
\centering
\includegraphics[width=0.9\textwidth, angle=0]
{./images/RIL-Expt-Setup1.eps}
%figure caption is below the figure
\caption{Hardware and software setup for series A \& B experiments}
\label{fig:RIL-Expt-Setup1} % Give a unique label
\end{figure*}
%%
Ideally, AFM can be implementation as a complete distributed task-allocation system where each agent selects its own task based on its own external perception about task-urgencies (i.e. attractive fields),  distances from tasks and internal task-sensitisation records. Such an implementation requires powerful robots with sophisticated sensors (camera, laser etc.) and sufficient computation and communication  capabilities. In that case, robots can keep  task-urgency information up-to-date  through suitable local communication  schemes with their peers who can monitor the tasks. By using suitable navigation and mapping modules, they can also accurately calculate the distances from tasks and navigate to tasks autonomously. Moreover, they also require necessary hardware to do the actual task, e.g. gripper for pick-up tasks.

However, in this study, we are particularly interested to find the suitable communication schemes that can effectively spread the attractive fields (task-urgencies) among robots. So we have simplified the complexities of a full-fledged implementation by using a centralized communication system  that effectively makes up the limitations of our robots.  For example, our robots are not  capable of sensing a task to estimate its urgencies, instead our centralized {\em task-perception server (TPS)} broadcast task information, e.g. task-urgencies, locations etc. to robots in certain time intervals. Within this interval, if some robots work on a task, they independently send their status, i.e. which task they are currently doing. From this status message,  TPS can re-calculate the task-urgencies and send them in next broadcast. 

Fig. \ref{fig:ccm} shows how three robots are attracted to two different tasks and their communications with TPS. Here although the robots are selecting task independently based-on the strength of their attractive fields to different tasks, they are depended on the TPS for task-information.

This centralized communication system can be converted into a decentralized one where robots can use local observation and communication with peers about tasks to estimate task-urgencies. In Chapter \ref{local-comm}, we present an emulation of this scenario where robots do not depend entirely on TPS for estimating task-urgencies, instead they get task information from TPS when they are very close to a task (inside a pre-defined task-boundary) or from local peers who know about a task via TPS.

In our current implementation, instead of doing any real work with powerful robots, we emulate a mock manufacturing shop-floor scenario that requires the robot only to travel among tasks. As discussed in Sec. \ref{expt-tools:btcom}, our robots do not have on-board CPU, they need a host PC to  control them using BTCom communication protocol. Thus our host-PC  runs one RCC for each physical robot. These RCCs also rely upon SwisTrack multi-robot tracking system for updating their real-time pose. So although our MRTA solution is distributed by design, we primarily used a centralized approach to implement it due to the limitations of our robots and the convenience of implementation. Below we describe the actual implementations of these components, i.e. D-Bus communication interfaces and detail implementations of TPS and RCC.
%%
\begin{table*}
\caption{D-Bus signal interfaces among software components.}
\label{table:dbus-interfaces}
\begin{center}
\begin{tabular}{|l|l|l|p{2in}|}
\hline D-Bus Signal &  Source & Destination  & Payload \\ 
\hline RobotPose & SwisTrack & RCC  & Robot-pose x, y and oientation (theta). \\ 
\hline TaskInfo & TPS & RCC & An array of all tasks' information each of them contains: task-id, time-stamp, task pose (x,y), task-urgency. \\ 
\hline RobotStatus & RCC & TPS & Robot's id and its currently executing task's id. \\ 
\hline RobotPeers & SwisTrack & RCC & List of IDs of peers of each robot within its communication range.  \\ 
\hline TaskNeighbour & SwisTrack & TPS &  List of IDs of robots that are co-located within a task's perception range.\\ 
\hline LocalTaskInfo & RCC & RCC & An array of known tasks' information.\\
\hline 
\end{tabular}
\end{center} 
\end{table*}
%%
\begin{figure*}
\begin{center}
\includegraphics[width=0.9\linewidth]{./images/concrete-arch} 
%\centering
\caption{General outline of {\em HEAD}. A RCC application has been split into two parts: one runs locally in server PC and another runs remotely, e.g., in an embedded PC.} 
\label{fig:concrete-arch}
\end{center}
\end{figure*}

Fig. \ref{fig:concrete-arch} outlines the placements of various software components of our multi-robot control architecture based on their functional characteristics and processing requirements \cite{Sarker2010control}. As shown in Fig. \ref{fig:RIL-Expt-Setup1}, each e-puck robot is controlled by a corresponding RCC. A RCC sends commands to the robot's firmware using BTCom protocol. A RCC consists of several Python modules. Each module represents a sub-process under a main process that ties all of them together by using Python's Multiprocessing module. Below we have described the detail design and implementation of these Python modules. All code are publicly accessible through GitHub repository\footnote{git://@github.com/roboshepherd/EpuckCentralizedClient.git,    
\textit{hash:}7e3af8902e64db3fa59e}.
%%
%%
\begin{table}
\caption{Data structures and events used by the RCC}
\begin{center}
\begin{tabular}{|l|l|}
\hline \textbf{Data structure} & \textbf{Related event(s)}\\ 
\hline \texttt{\texttt{mRobotID}} & - \\ 
\hline \texttt{mRobotPose} & \texttt{mRobotPoseAvailable}\\ 
\hline \texttt{mTaskInfo} & \texttt{mTaskInfoAvailable}\\ 
\hline \texttt{mSelectedTask} & \texttt{mSelectedTaskAvailable}\\
 &  \texttt{mSelectedTaskStarted}\\
 &  \texttt{mTaskTimedOut}\\
 \hline 
\end{tabular}
\end{center}
\label{table:data-mgr}
\end{table} 

In the implementation of RCC, we have employed a data and event management process called \texttt{DataManager} that acts as a data warehouse and event management centre for RCC. Table \ref{table:data-mgr} list the major data structures and corresponding event channels of \texttt{Data Manager}. Here \texttt{mRobotID}, an integer type data,  represents the e-puck robot's marker ID (converted to decimal number from the binary code) which uniquely identifies a robot from others. This is given as a command-line argument during RCC start-up. We have used Python {\em dictionary} type data structure for all other data structures that are managed by the Python Multiprocessing's {\em Manager()} object. Any other process e.g. \texttt{TaskSelector}, can access \texttt{DataManager}'s data and event channels locally  by taking a reference of \texttt{DataManager} object from the Multiprocessing's parent process. \texttt{DataManager} object also runs a tiny TCP/IP server process powered by the Multiprocessing's {\em RemoteManager()} interface. So, if necessary,  any other process e.g. \texttt{DeviceController}, can access all of the DataManger's data structures and event channels remotely by instantiating a proxy client  that connects to this embedded TCP/IP server of \texttt{DataManager} and  fetch data from it.

We have employed two D-Bus communication modules in RCC: \texttt{SignalListener} and \texttt{SignalEmitter}, that are responsible for listening and emitting D-Bus signals respectively. \texttt{SignalListener}, has subscribed to D-Bus session bus for listening  to D-Bus \texttt{RobotPose} and \texttt{TaskInfo} signals that are discussed above. \texttt{SignalListener} uses two call-back functions that handles both of these signal reception events. For example when SwisTrack emits \texttt{RobotPose} signal  the corresponding handler function becomes activated and receive this \texttt{RobotPose} signal's payload data (i.e. x, y , theta). It then makes a copy of these data  to \texttt{DataManager}'s \texttt{mRobotPose} data structure and label them as dictionary key/value pairs, where x, y, theta etc. becomes the dictionary keys. In addition to copying the data, \texttt{SignalListener} also set the \texttt{DataMager}'s   \texttt{mRobotPoseAvailable} event to {\em \texttt{True}}. In consequence, those processes that are waiting for \texttt{mRobotPose} data, e.g. \texttt{TaskSelector}, finishes their waiting and try to access this newly arrived \texttt{mRobotPose} data. After reading to this data they marks this \texttt{mRobotPoseAvailable} event as  {\em \texttt{False}} so that this pose data can be treated as outdated and waiting processes can wait for new pose update. This strategy ensures the consistent and real-time data read/write by all subscribing processes.

Similar to the \texttt{SignalListener}, \texttt{SignalEmitter} makes use of Python\\ {\em sched} module that enables it to check periodically \texttt{mSelectedTaskStarted} event and emit a robot's task status containing signal, \texttt{RobotStatus}.  This is done by subscribing to the  \texttt{mSelectedTaskStarted} event channel. When a robot executes a task, this event channel becomes  activated by\\ \texttt{DeviceController} (discussed below).\\ At a very close time, \texttt{SignalEmitter} gets this event update and finishes waiting for this event. It then picks up the \texttt{mSelectedTask} data from \texttt{DataManager} and prepare the \texttt{RobotStatus} signal and emits it to the session bus. Upon a successful emission event, it clears \texttt{ mSelected TaskStarted} event so that only one \texttt{RobotStatus}  signal is emitted per task-cycle.

\texttt{TaskSelector} works in the application layer of our multi-robot control architecture. It plugs the AFM algorithms into RCC to select task based-on \texttt{DataManger}'s event notifications , i.e. \texttt{mRobotPoseAvailable} and\\ \texttt{mTaskInfoAvailable} and upon running task-allocation algorithm it updates  \texttt{mSelectedTask} (and \texttt{mSelectedTaskAvailable}) with selected task information.
%%
\begin{figure*}
\centering
\includegraphics[width=0.9\linewidth,height=11cm]
{./images/rcc-device-controller-state.eps}
%figure caption is below the figure
\caption{State diagram of \texttt{DeviceController} module}
\label{fig:dc-states} % Give a unique label
\end{figure*}

The final code that moves a robot to desired task location or make random-walk resides in \texttt{DeviceController} module. This is also a separate sub-process of our Python Multiprocessing based mother process. It waits for the \texttt{DataManager}'s \texttt{mRobotPoseAvailable} and \texttt{mSelectedTaskAvailable} events. When \texttt{TaskSelector} sets  \texttt{mSelectedTaskAvailable} event,\\ \texttt{DeviceController} sub-process checks the Bluetooth link-connectivity with physical robot. In case of successful task start-up it sets\\ \texttt{mSelectedTaskStarted} event that, in turn, triggers \texttt{SignalEmitter} to emit a D-Bus signal publishing the robot's currently engaged task. The full state switching policies of\\ \texttt{DeviceController} is illustrated in Fig. \ref{fig:dc-states}. Externally we can observe two distinct physical state of a robot: it is either idle or in motion (separated by dotted line). These two physical states are mapped into several logical steps:\\
%%
\textbf{DeviceUnavailable: }
Initially, \texttt{DeviceController} sets it state as \textit{DeviceUnavailable} (e.g. not connected with Bluetooth link) and after a fixed short-time intervals it checks whether the device has connected to host-PC, i.e. after the  wireless link becomes up. In that case, \texttt{DeviceController} switches its state to \textit{DeviceAvailable} (i.e device connected). We can see that from every other state, device can come to this unavailable state (shown by dotted arrow) when the  link is lost e.g. in case of robot's low battery or any other disconnection event (i.e device disconnected).\\
%%
\textbf{DeviceAvailable: }
\texttt{DeviceController} stays in this state until\\ \texttt{Data-Manager}'s mSelectedTaskAvailable event fires ({\em Device connected, no task selected}). Then it switches to either \textit{MoveToTask} or \textit{RandomWalk} state depending on the selected task.  \texttt{DeviceController}  returns to this state from \textit{RandomWalk}, \textit{MoveToTask} or \textit{AtTask} states after a pre-set task time-out period has elapsed.  In that case it triggers the \texttt{DataManager}'s \texttt{mTaskTimedOut} event.\\
%%
\textbf{RandomWalk: }
Robot can random walk in two cases: 1) when \texttt{TaskSelector} selects this random-walk task or 2) when the robot can not get its pose information for a moment. The latter helps the pose tracker to recover the robot-pose from a crowd of robots. Robot continues to do random-walk until it's task time-out period elapses or it regains it pose remains unavailable from the pose tracker (i.e. random-walk pending).\\
%%
\textbf{MoveToTask: }
In this state, robot takes step-by-step navigation approach to reach a task boundary. Until the robot reaches the task boundary ({\em Away from task}), in every navigation-step it adjusts its heading to task based on both  robot and task pose information and then makes a fixed-time translation movement. In worse cases, when time-out happens early before reaching a task  \texttt{DeviceController}\\ switches from this state to\textit{ DeviceAvailable} state. However, if the same task is selected immediately, it is more likely that it will go to \textit{AtTask} state in next step.
%%
\textbf{AtTask: }
In this state  \texttt{DeviceController} discovers itself neat the task and normally until task time-out happens (i.e. task pending) it stays at this state.

We have added three new D-Bus signal interfaces in this version of our implementation. They are briefly discussed below.\\
\textbf{\texttt{RobotPeers}: }This signal is emitted by SwisTrack to each robot's signal path in a common \texttt{ac.uk.newport.ril.SwisTrack} interface. The payload of this signal contains the list of IDs of peers of each robot within it's $r_{comm}$.  These peer-IDs are extracted by analysing the captured image frame.  This signal is caught by RCCs and used in emitting the \texttt{LocalTaskInfo} signal (discussed below).\\
\textbf{\texttt{TaskNeighbohood}: }This signal is emitted by SwisTrack for TPS and the payload of this signal contains the list of IDs of robots that are co-located within a task's perception range, $r_{task}$. TPS catches one signal per task and based-on the robot IDs, it emits the \texttt{TaskInfo} signal to those robot's RCC path (as discussed in Sec. \ref{afm:impl}).\\ 
\textbf{\texttt{LocalTaskInfo}: }This signal is emitted by RCCs to their peers that are co-located within the same communication range $r_{comm}$. The payload of this signal contains the known task information of a  RCC. This task-information can be gathered either through task-perception (via \texttt{TaskInfo} signal received from TPS) or via communications i.e. through \texttt{LocalTaskInfo} signals from its peers.

%% local
As shown in Fig. \ref{fig:local-setup}, RCCs disseminate task information to each other by\\ \texttt{LocalTaskInfo} D-Bus signal. The contents of task information are physical locations of tasks and their urgencies. However as our robots are incapable of sensing task directly. So it relies on TPS for a task-perception signal, \texttt{TaskInfo}, that contains the actual task location and urgency. When a robot $r_i$ comes within $r_{task}$ of a task $j$, SwisTrack reports it to TPS (by \texttt{TaskNeighbors} signal) and TPS then gives it current task information to $r_i$ by  \texttt{TaskInfo} signal. As we have discussed, TPS catches feedback signals from robots via \texttt{RobotStatus} signal. This can be used to inform TPS about a robot's current task id, its device status and so on. TPS uses this information to update relevant part of task information such as, task-urgency. This up-to-date information is encoded in next \texttt{TaskInfo} signal.

From the above discussions, we can see that our base implementation of RCC's task-allocation (i.e. \texttt{TaskSelector}) is almost unchanged in this local implementation. The only thing we need to extend is the D-Bus signal reception and emission interfaces that catches the above signals and put the signal payload in \texttt{DataManager}. For the sake of simplicity, we have merges the perceived \texttt{Task-}\\ \texttt{Info} with communicated \texttt{LocalTaskInfo} into one so that \texttt{TaskAllocator} always gets all available task information. We have not made any major change in other modules of RCC, i.e. \texttt{DeviceController}. The full Python implementation of this RCC is available for download from the GitHub repository\footnote{http://github.com/roboshepherd/EpuckDistributedClient }.

In our base implementation TPS periodically broadcasts \texttt{TaskInfo }signals to all robots. But in this local version, TPS only emits \texttt{TaskInfo} signal when a robot is within a task's perception range, $r_{task}$ based-on the \texttt{TaskNeighbour} signal from SwisTrack. For this additional interface, we have extended D-Bus \texttt{SignalListener} to catch this additional D-Bus signal.  No major changes are done in the other parts of TPS implementation. The full Python implementation of TPS is available for download from the GitHub repository\footnote{http://github.com/roboshepherd/DitributedTaskServer}.
%%==================================================================
\section{Results}
\label{sec:res}
%%
In this section we have presented our experimental results. We ran those experiments for about 40 minutes and averaged them over five iterations. 
%%-------------------------------------------------
\subsection*{Shop-floor work-load history}
In our experiments we have defined shop-floor work-load in terms of task urgencies. For example, Eq. \ref{eqn:task-urgency-prod-init} shows how we have calculated initial production work-load of our manufacturing shop-floor scenario. Fig. \ref{fig:raw-urgencies}  show the dynamic changes in task-urgencies for the single iteration of each experiment. The fluctuations in these plots are resulted from the different levels of task-performance of our robots. In case of Series D, we can see that an unattended task, \textit{Task4}, was not served by any robot for a long period and later it was picked up by some of the robots. 
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SA-PlotUrgencyLog-2010Apr30-095755.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SB-PlotUrgencyLog-2010May10-115549.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SC-PlotUrgencyLog-2010Feb15-171017.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SD-PlotUrgencyLog-2010Feb17-112141.eps}}
\caption{Changes in task-urgencies} 
\label{fig:raw-urgencies} 
\end{figure}
%%
In order to measure the task-related work-loads on our system we have summed up the changes in all task-urgencies over time. We call this as {\em shop-floor work-load history} and formalized as follows. Let $ \phi_{j, q}$ be the urgency of a task $j$ at $q^{th}$ step and $\phi_{j, q+1}$ be the task urgency of $(q+1)^{th}$ step. We can calculate the sum of changes in urgencies of all $M$ tasks at $(q+1)^{th}$ step:
\begin{equation} 
\Delta \Phi_{j, q+1} = \sum_{j=1}^{M} (\phi_{j, q+1} - \phi_{j, q})
\label{eqn:Delta-Phi}
\end{equation}
From Fig. \ref{fig:urgency-stat} shows the dynamic shop-floor workload for all four series of experiments. From these plots, we can see that initially the sum of changes of task urgencies (shop-floor workload) is going towards negative direction. This implies that tasks are being served by a high number of robots. 
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SA-8robots2tasks-TaskUrgencyStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SB-TaskUrgencyStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SC-TaskUrgencyStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SD-TaskUrgencyStat.eps}}
\caption{Shop-floor workload change history} 
\label{fig:urgency-stat} 
\end{figure}
%%
%%----------------------------------------------------------------
\subsection*{Ratio of active workers}
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SA-Plasticity-8robots2tasks.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SB-WorkerRatio.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SC-Local50cm-Plasticity.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SD-Local1m-Plasticity.eps}}
\caption{Self-organized allocation of robots} 
\label{fig:worker-stat} 
\end{figure}
%%
From Fig. \ref{fig:worker-stat}, we can  see that in production stage, when work-load is high, many robots are active in tasks. Here active workers ratio is the ratio of those robots that work on tasks to the total number of robots $N$ of a particular experiment.   Here we can see that this ratio varies according to the shop-floor work-load changes.
%%-------------------------------------------------------------
\subsection*{Shop-task performance}
%%
\begin{figure}
\centering
\subfloat[APCD]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/apcd.eps}}
%\hspace{0.2cm}
\newline
\subfloat[APMW]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/apmw.eps}}
\label{fig:mfg-stat} 
\end{figure}
%%
In our manufacturing shop-floor scenario, we have calculated the APCD and APMW as shown in Fig. \ref{fig:mfg-stat}. For Series A we have got  average production completion time 111 time-steps (555s) where sample size is (5 x 2) = 10 tasks, SD = 10 time-steps (50s). According to Eq. \ref{eqn:min-pmm}, our theoretical minimum production completion time is 50 time-steps (250s) assuming the non-stop task performance of all 8 robots with an initial task urgency of 0.5 for all 2 tasks and task urgency decrease rate $\Delta \Phi_{DEC }$ = 0.0025 per robot per time-step.  Hence, Eq. \ref{eqn:appd} gives us APCD, $\zeta$ = 1.22 which means that in Series A experiments, it took 1.22 times more time (305s) than the estimated minimum production completion time (250s). For Series B, we have got average production completion time 165 time-steps (825s) where sample size is (5 x 4) = 20 tasks, SD = 72 time-steps (360s).  Hence, Eq. \ref{eqn:appd} gives us APCD, $\zeta$ = 2.3. For Series C we have got average production completion time 121 time-steps (605s) with SD = 36 time-steps (180s). For Series D,  average production completion time is 123 time-steps (615s) with SD = 40 time-steps (200s). According to Eq. \ref{eqn:min-pmm}, our theoretical minimum production completion time is 50 time-steps (250s) as discussed in Sec \ref{afm:results}.  The values of APCD are as follows. For Series C, $\zeta$ = 1.42 and for Series D, $\zeta$ = 1.46. For both series of experiments APCD values are very close.

For APMW, Series A experiments give us an average time length of 369 time-steps (1845s).  In this period we calculated APMW and it is 1 time-step with SD = 1 time-step (5s) and $\Delta \Phi_{INC}$ = 0.005 per task per time-step. This shows a very low APMW ($\chi$ = 0.000235) and a very high robustness of the system. For Series B experiments, from the average 315 time-steps (1575s) maintenance activity of our robots per experiment run, we have got APMW, $\chi$ = 0.012756 which corresponds to the pending work of 3 time-steps (15s) where SD = 13 time-steps (65s). This tells us the robust task performance of our robots which can return to an abandoned task within a minute or so. The APMW of Series C experiments give us an average time length of 359 time-steps (1795s). In this period we calculated APMW and it is 5 time-steps with SD = 17 time-steps and $\chi$ = 0.023420. For Series D experiments, from the average 357 time-steps (1575s) of maintenance activity of our robots per experiment run, we have got APMW, $\chi$ = 0.005359 which corresponds to the pending work of 2 time-steps (10s) where SD = 7 time-steps.
%%-------------------------------------------------
\subsection*{Task specializations}
We have measured the task-specialization of the robots based-on their peak value of sensitization. This maximum value represents how long a robot has repeatedly been selecting a particular task. Since tasks are homogeneous we have considered the maximum sensitization value of a robot among all tasks during an experiment run. This value is then averaged for all robots using the following  equation. 
%%
\begin{equation}
K^G_{avg} = \frac{1}{N}\sum_{i=1}^{N} \max_{j=1}^M\left ( k^i_{j, q} \right ) 
\label{eqn:K-G}
\end{equation}
%%
If a robot $r_i$ has the peak sensitization value $k^i_j$ on task $j$ ($j \in M$ tasks)  at $q^{th}$ time-step, Eq. \ref{eqn:K-G} calculates the average of the peak task-specialization values of all robots for a certain iteration of our experiments. We have also averaged the time-step values ($q$) taken to reach those peak values for all robots using the following equation.
%%
\begin{equation}
Q^G_{avg}= \frac{1}{N}\sum_{i=1}^{N} q^i_{k=k_{max}}
\label{eqn:Q-G}
\end{equation}
In Eq. \ref{eqn:Q-G}, $q^i_{k=k_{max}}$ represents the time-step of robot $r_i$  where its sensitization value $k$ reaches the peak $k_{max}$ as discussed above. By averaging this peak time-step values of all robots we can have an overall idea of how many task-execution cycles are spent to reach the maximum task-specialization value $K^G_{avg}$.
%% S-A
\begin{table}
\centering
\caption{Peak task-sensitization values of robots in a Series A experiment.}
% 30Apr expt.
\begin{tabular}{|c|c|c|c|}
\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\ 
\hline 1 & 0.54 & 64 & Task1\\
\hline 4 & 0.32 & 14 & ,,\\
\hline 5 & 0.27 & 11 & ,,\\
%%
\hline 3 & 0.47 & 63 & Task2\\
\hline 2 & 0.46 & 64 & ,,\\
\hline 6 & 0.20 & 10 & ,,\\
\hline 7 & 0.18 & 4 & ,,\\
\hline 8 & 0.15 & 3 & ,,\\
\hline 
\end{tabular} 
\label{table:K-G-SA}
\end{table}
%% S - B
\begin{table}
\centering
\caption{Peak task-sensitization values of robots in a Series B experiment.}
\begin{tabular}{|c|c|c|c|}
% Apr 18 Feb-3 expt
\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
\hline 24 & 0.41 & 29 & Task1\\
\hline 13 & 0.31 & 19 & ,,\\
\hline 16 & 0.18 & 4 & ,,\\
%% 
\hline 1 & 0.64 & 66 & Task2\\
\hline 35 & 0.34 & 12 & ,,\\
\hline 5 & 0.28 & 14 & ,,\\
\hline 22 & 0.18 & 20 & ,,\\
\hline 17 & 0.16 & 6 & ,,\\
\hline 3 & 0.14 & 12 & ,,\\
%%
\hline 9 & 0.68 & 66 & Task3\\
\hline 6 & 0.43 & 71 & ,,\\
\hline 15 & 0.19 & 4 & ,,\\
\hline 14 & 0.15 & 4 & ,,\\
\hline 31 & 0.14 & 4 & ,,\\
%%
\hline 19 & 0.22 & 12 & Task4\\
\hline 12 & 0.16 & 10 & ,,\\
\hline 
\end{tabular} 
\label{table:K-G-SB}
\end{table}
Table \ref{table:K-G-SA} and Table \ref{table:K-G-SB} show the peak sensitization values of Series A and Series B experiments respectively.  Based on Eq. \ref{eqn:K-G} and Eq. \ref{eqn:Q-G}, we have got the peak task-sensitization $K^G_{avg} 
$ values: 0.40 (SD=0.08)  and 0.30 (SD=0.03), and their respective time-step $Q^G_{avg}$ values: 38 (SD=13) and 18 (SD=5) time-step.  They are shown in Fig. \ref{fig:K-G-SA-SB} and Fig. \ref{fig:Q-G-SA-SB}. Here we can see that the robots in Series A had higher chances of task-specialization than that of Series B experiments.
%%
% Series C raw data
\begin{table}
\centering
\caption{Peak task-sensitization values of robots in a Series C experiment.}
% 16Feb-1 expt
\begin{tabular}{|c|c|c|c|}
\hline\textbf{ Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
\hline 16 & 1.00 & 52 & Task1\\
\hline 12 & 0.58 & 24 & ,,\\  
\hline 1 & 0.16 & 2 & ,,\\ 
\hline 13 & 0.13 & 1 & ,,\\
%%
\hline 9 & 1.00 & 41 & Task2\\
\hline 3 & 0.55 & 23 & ,,\\ 
\hline 19 & 0.24 & 6 & ,,\\
\hline 35 & 0.24 & 6 & ,,\\
\hline 15 & 0.13 & 1 & ,,\\
\hline 33 & 0.13 & 2 & ,,\\ 
%%
\hline 6 & 0.61 & 29 & Task3\\
\hline 31 & 0.59 & 35 & ,,\\ 
\hline 5 & 0.13 & 1 & ,,\\ 
%%
\hline 17 & 0.36 & 10 & Task4\\
\hline 20 & 0.09 & 1 & ,,\\ 
\hline 22 & 0.09 & 1 & ,,\\ 
 \hline 
\end{tabular} 
\label{table:K-Q-SC}
\end{table}
%% Series D
\begin{table}
\centering
\caption{Peak task-sensitization values of robots in a Series D experiment.}
%% 17 feb-1 expt
\begin{tabular}{|c|c|c|c|}
\hline\textbf{ Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
\hline 19 & 1.00 & 34 & Task1\\
\hline 35 & 1.00 & 60 & ,,\\
\hline 24 & 0.41 & 16 & ,,\\
\hline 12 & 0.20 & 6 & ,,\\  
%%
\hline 1 & 1.00 & 41 & Task2\\
\hline 31 & 1.00 & 47 & ,,\\
\hline 22 & 0.40 & 10 & ,,\\
\hline 9 & 0.38 & 12 & ,,\\
\hline 15 & 0.16 & 2 & ,,\\
\hline 33 & 0.13 & 1 & ,,\\ 
%%   
\hline 5 & 0.92 & 70 & Task3\\ 
\hline 13 & 0.74 & 36 & ,,\\
%% 
\hline 17 & 0.76 & 62 & Task4\\ 
\hline 6 & 0.22 & 4 & ,,\\ 
\hline 3 & 0.13 & 2 & ,,\\
\hline 16 & 0.13 & 1 & ,,\\ 
\hline 
\end{tabular}
\label{table:K-Q-SD} 
\end{table}
%%
\begin{figure}
\centering
\subfloat[Task-sensitization (K)]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/K-Group.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Time-steps (Q)]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/Q-Group.eps}}
\caption{ Overall task-specialization of robot groups based on Peak task-sensitization values.}
\label{fig:task-specialization} 
\end{figure}
%%
%% ------ Single robot----
\begin{figure}
\centering
\includegraphics[width=\linewidth, angle=0]{images/TaskSpecialization-task3-10may-1.eps}
\caption{Task specialization on Task3 for a Series B experiment.}
\label{fig:k-single-task-SB} 
\end{figure}
%%
Fig. \ref{fig:k-single-task-SB} shows us the task specialization of five robots on Task3 in a particular run of Series B experiment. This shows us how some of the robots can specialize (learn) and de-specialize (forget) tasks over time.
%%-------------------------------------------------
\subsection*{Robot motions}
We have aggregated the changes in translation motion of all robots over time. Let $u_{i,q}$ and $u_{i,q+1}$ be the translations of a robot $i$ in two consecutive steps. If the difference between these two translations be $\delta u_{i}$, we can find the sum of changes of translations of all robots in $(q+1)^{th}$ step using the following equation.
\begin{equation}
\Delta U_{q+1} = \sum_{i=1}^{N} \delta u_{i, q+1} 
\label{eqn:Delta-Tr}
\end{equation}
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SA-8robots-DeltaTranslationStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SB-DeltaTranslationStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.84\linewidth, angle=0]
{images/SC-DeltaTranslationStat.eps}}
\newline
\subfloat[Series D]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SD-DeltaTranslationStat.eps}}
\caption{Sum of the translations of robots} 
\label{fig:translation-stat}
\end{figure}
%%
The sum of translations of robots from our experiments are plotted in Fig. \ref{fig:translation-stat}. In this plot we can see that robot translations also vary over varying task requirements of tasks. In this plot we can see that robot translations also vary over varying task requirements of tasks. 
%%%-------------------------------------------------
\subsection*{Communication load}
%%% Communication load 
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SA-8Robot-SignalingFreqStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SB-SignalingFreqStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SC-Local-500cm-SignalingFreqStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.96\linewidth, angle=0]
{images/SD-Local-1m-SignalingFreqStat.eps}}
\caption{Frequency of \texttt{TaskInfo} signalling of (a) and (b) by TPS and (c) and (d) by local peers.} 
\label{fig:signal-frequency-stat}
\end{figure}
%%
%%%% Single robot- number of peers
\begin{figure}
\centering
\hspace*{0.5cm}
\subfloat[Series C]{\includegraphics[width=0.96\linewidth]{images/Robot12-16feb-1-LocalSignals.eps}}
\newline
\subfloat[Series D]{\includegraphics[width=0.96\linewidth]{images/Robot12-17feb-3-LocalSignals.eps}}
\caption{\small \texttt{LoaclTaskInfo} (P2P) signals caught by Robot12 in (a) Series C and (b) Series D experiment}
\label{fig:local-single-robot-signal} 
\end{figure}
%%
Fig. \ref{fig:signal-frequency-stat} (a) and (b) shows the number of received \texttt{TaskInfo} signals by each robot in Series A and Series B experiments. Since the duration of each time-step is 50s long and TPS emits signal in every 2.5s, there is an average of 20 signals in each time-step. The overall P2P task information signals of both of these local modes are plotted in Fig. \ref{fig:signal-frequency-stat} (c) and (d). As an example of P2P signal reception of a robot,  Fig. \ref{fig:local-single-robot-signal} show the number of received signals by Robot12 in two local experiments. It states the relative difference of peers over time in two local cases.
%==================================================================
\section{Discussions}
\label{sec:discuss}
%%
\textbf{Self-regulated DOL}. From our experimental results, we have noted several aspects of self-regulated DOL that exposes the power of AFM. As we have pointed out that this self-regulated DOL, as observed in biological and human social systems, needs to satisfy several important characteristics, e.g. plasticity, task-specialization. In addition to satisfying those basic qualities, AFM has demonstrated many other aspects. Our self-regulated robots, driven by AFM, effectively handle the dynamic work-load in our manufacturing shop-floor. They can dynamically support the need to work on currently demanding tasks, if there any. The variations of active worker ratio supports this. 

From the self-organized worker allocations of AFM, it is clear to us that although in larger system (Series B) the degree of variations of active-worker ratio can show us significantly unpredictable patterns, nevertheless the self-regulated rules drive the robots to respond to the dynamic needs of the system. This means that AFM can sufficiently produce the plasticity of DOL in order to meets the dynamic work-load of the system.

\textbf{Learning and Forgetting}. From the individual and group-level task-\\ specialization, we can see that robots can maintain both task-specialization and flexibility. In a self-organized system, it is very common that only a few individuals specialize on tasks and others generally do not. From two samples data sets, we can see that in particular runs of Series A and Series B experiments, task-sensitization values of  only 2-3 robots reach above the group-level average score. Thus in both types of experiments, robots exhibit similar task-specialization behaviours. 

From task-sensitization we can also see that a limited number of robots are specialized in tasks. Thus most of the other robots are flexible in selecting any tasks as their task-specializations do not bind them to particular tasks.

\textbf{Concurrency and robustness}. As a consequence of fewer robots specializing in tasks, we can also see that robots can concurrently  consider different tasks without being biased to a particular task all the time. Our experiments also show us the robust DOL as in case of  both high and low work-loads present in the system. This is evident from the manufacturing shop-floor task performance during PMM and MOM. For example,  in case of Series B experiments APMW was 13 time-steps (65s) which corresponded  to pending work-load of 0.065 unit for a single robot. Thus, on an average, before the work-load exceeded by about 13 percent of initial work-load, robots were able to respond to  a task.

\textbf{Communication load.} In these experiments we used a centralized communication system (source of attractive fields) that serves the robot with necessary task-perception information. Although our robot-controllers software RCC was also co-located in the same host-PC, they can be distributed to several PCs or robot's on-board PCs. Our centralized communication system has the advantage of minimising the communication load and the disadvantage of a single point of failure as well as single point of load. In the next chapter we present how the task perception can be decentralized by P2P communications among RCCs.

\textbf{Scaling-up}. We have observed the effect of scaling-up the robot team size. The system size of Series B is double of that of Series A in terms of robots, tasks and experiment arena. Keeping a fixed ratio of robot-to-task and task-to-arena we have intended to see the scaling effects in our experiments. Here we see that both systems can show sufficient self-regulated DOL, but task-performance of both systems varies significantly. For example, the value of APCD in Series B is higher by 1.08. This means that performance  is decreased in Series B experiments despite having the resources in same proportion in both systems. This occurs partly due to the greater stochastic effects found in task-allocation in a larger system, e.g. presence of more tasks produce higher stochastic behaviours in robot's task selection.

Similarly we can see that in larger system robots have less chances to specialize on tasks, as the Series B experiments show us that the overall average task-specialization of the group $K^G_{avg}$ is lower by 0.10 and it lasts for significantly less time (the difference of $Q^G_{avg}$  of both systems is 20 time-steps). Thus, in a large group, robots are more likely to switch among tasks more frequently and this produces more translation motions which cost more energy (e.g. battery power) in task-performance.

\textbf{Comparisons between local communication and sensing strategies:} Results from Series C and Series D experiments show us many similarities and differences with respect to the results of Series A and Series B experiments. Both Series C and Series D experiments show similar APCD values: 1.42 and 1.46 respectively, which are significantly less than Series B experiment result (APCD = 2.3) and are close to Series A experiment result (APCD = 1.22). This means that for large group, task-performance  is efficient under LSLC strategy (Series C and Series D) comparing with their GSNC counterpart (Series B).

Besides, in terms of task-specialization, the overall task-specialization of group in Series C ($K^G_{avg}$ = 0.4) is  closer to that of Series A experiments ($K^G_{avg}$ = 0.39) and interestingly, the value of  Series D ($K^G_{avg}$ = 0.27) is  much closer to that of Series B experiments ($K^G_{avg}$ = 0.30). So task-specialization in large group under LSLC strategy shows higher performance than their GSNC counter part. Besides task-specialization happens much faster under LSLC strategy as we can see that the average time to reach peak sensitization values  of the group,  $Q^G_{avg}$ in Series C is lower than that of Series A values by 25 time-steps.

\begin{table}
\begin{center}
\caption{Sum of translations of robots in Series A-D experiments.}
\begin{tabular}{|c|c|c|}
\hline \textbf{Series} & \textbf{Average translation (m)} & \textbf{SD} \\ 
\hline A & 2.631 & 0.804\\ 
\hline B & 13.882 & 3.099\\
\hline C & 4.907 & 1.678\\
\hline D & 4.854 & 1.592\\
\hline
\end{tabular}
\label{table:motion-cmp} 
\end{center}
\end{table}
%%
From the robot motion profiles found in all four series of experiments, we have found that under LSLC strategy, robot translations have been reduced significantly. Table \ref{table:motion-cmp} summarizes the average translations done by robots in all four series of experiments. From this table we can see than Series C and Series D show about 2.8 times less translation than that in Series B experiments. The translation of 16 robots in Series C and Series D experiments are approximately double (1.89 times) than that of Series A experiments with 8 robots.  Thus the energy-efficiency under LSLC strategy seems to be higher  than that under GSNC strategy.

From the above results we can see that large group robots achieve better MRTA under LSLC strategy. The local sensing of tasks prevents them to attend a far-reaching task which may be more common under global sensing strategy. However, as we have seen in Fig. \ref{fig:raw-urgencies-SC-SD}
some tasks can be left unattended for a long period of time due to the failure to discover it by any robot. For that reason we see that the values of APMW is slightly higher under LSLC strategy. But this trade-off is worth as LSLC strategy provides superior self-regulated MRTA in terms of task-performance, task-specialization and energy-efficiency. 
%%================================================================
\section{Conclusions}
\label{sec:conc}
The benefits of deploying a large number of robots in dynamic multi-tasking environment can not be fully realized without adopting an effective communication and sensing strategy for a given multi-robot system. This study has focused on comparing two bio-inspired  communication and sensing strategies in producing self-regulated MRTA by an interdisciplinary model of DOL, AFM. Under the GSNC strategy, AFM has produced the desired self-regulated MRTA among a group of 8 and 16 robots. This gives us the evidence that AFM can successfully solve the MRTA issue of a complex multi-tasking environment like a manufacturing shop-floor. Under the LSLC strategy, AFM can also produce the desired self-regulated MRTA for 16 robots with different communication and sensing ranges.

From our comparative results, we can conclude that for large group of robots,  degradation in  task-performance and task-specialization of robots are likely to occur  under GSNC strategy that relies upon a centralized communication system. Thus GSNC strategy can give us better performance when the number of tasks and robots are relatively small. This confirms us the assertions made by some biologists that self-regulated DOL among small group of individuals can happen without any significant amount of local communications and interactions. However, our findings suggest that task-specialization can still be beneficial among the individuals of a small group which contradicts the claim that small groups only posses the generalist workers, but not the specialists.

On the other hand, LSLC strategy is more suitable for large group of individuals that are likely to be unable to perform global sensing and global communications with all individuals of the group. The design of communication and sensing range is still remained as a critical research issue. However, our results suggest that the idea of maximizing information gain is not appropriate under a stochastic task-allocation process, as more information causes more task-switching behaviours that lowers the level of task-specialization of the group. This might not be the case under a deterministic task-allocation scheme where more information leads to better and optimum allocations, but that is limited to a small group of individuals. Nevertheless, despite having the limited communication and sensing range, LSLC strategy helps to produce comparatively better task-allocation with increased task-specialization and significantly reduced motions or savings in energy consumption.
%%===========================================================
%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix%% \section%% \label{}
%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \cite{key}         ==>>  [#]
%%   \cite[chap. 2]{key} ==>> [#, chap. 2]
%%

%% References with bibTeX database:
\bibliographystyle{./elsart/elsarticle-num}
\bibliography{ras1}
%% Authors are advised to submit their bibtex database files. They are
%% requested to list a bibtex style file in the manuscript if they do
%% not want to use elsarticle-num.bst.
%% References without bibTeX database:
% \begin{thebibliography}{00}
%% \bibitem must have the following form:
%%   \bibitem{key}...
%%
% \bibitem{}
% \end{thebibliography}
\end{document}
%%
%% End of file `elsarticle-template-num.tex'.